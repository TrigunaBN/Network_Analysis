{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "import string\n",
    "\n",
    "import tweepy                  #Getting twitter data like tweets, followers, friends\n",
    "\n",
    "import nltk\n",
    "from textblob import TextBlob  #Sentiment analysis\n",
    "\n",
    "import networkx as nx          #Drawing & analyzing network\n",
    "\n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "This notebook contains the project which I've carried out for the course Analysis of Large Scale Social Networks (https://onderwijsaanbod.kuleuven.be/syllabi/e/H0T26AE.htm#activetab=begintermen_idp5387920) <br>\n",
    "\n",
    "## Main goal of this notebook\n",
    "The goal is to analyze the network of twitter users who tweeted regularly about #Brexit during the month of April, 2019.\n",
    "\n",
    "## Activities carried out in this notebook\n",
    "- Collect all the original tweets with #Brexit in English language in the month of April, 2019. Retweets not collected, but only count of retweets is noted. This is done using <b><i>tweepy</i></b> package. <i>(Note that, since I am using free developer version of twitter api, it is only possible to collect the tweets that are tweeted over the past 1 week. So in order to collect the tweets for the entire month of April, it was necessary to collect the data during every week in April).</i>\n",
    "- Perform sentiment analysis on all these tweets. This is done using <b><i>textblob</i></b> package. Only the sentiment polarity is considered here. Polarity value ranges between -1 and +1. Polarity values between -1 & 0 means that the twitter users feel negative about #Brexit, and polarity values between 0 & +1 means that the twitter users feel positive about #Brexit. \n",
    "- Divide the data into four parts, each representing a week in April. The idea is to analyze the network of twitter users who have tweeted regularly (each week) about #Brexit. For further simplifying the network analysis only those twitter users are considered whose tweets are retweeted at least 10 times during each of the four weeks of April. The idea is to analyze twitter users whose opinion about #Brexit is deemed valuable in twitter.\n",
    "- From the above criteria, it was found that 240 twitter users, also called <i>nodes</i> or <i>vertices</i>, have tweeted regularly in English about #Brexit during the month of April, 2019. The next step is to find the possible <i>edges</i> between the nodes. This is also done using tweepy package. There are three possible types of edges, i) source node follow destination node, ii) destination node follow source node, and iii) mutal following relationship (meaning source node & destination node follow each other).\n",
    "- The next activitiy carried out is constructing the social network. This is done using <b><i>networkx</i></b> package. For simplicity, the network is contructed only using mutually following edges.\n",
    "- The next activity carried out is finding out the properties in the social network such as Betweenness, Centrality etc.\n",
    "- Then different community detection algorithms are applied to the twitter network. The community detection algorithms are checked with the sentiments in each of the community. The idea is to evaluate the communitiy detection algorithms depending on how much the sentiments of twitter users about #Brexit vary.\n",
    "\n",
    "\n",
    "#### The usernames of twitter users in the network are not displayed. They are mapped into ids like user_0, user_1... <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_credentials = dict()\n",
    "#These are the credentials obtained by setting up your twitter developer account\n",
    "t_credentials['CONSUMER_KEY'] = '-----------------'  \n",
    "t_credentials['CONSUMER_SECRET'] = '-----------------'\n",
    "t_credentials['ACCESS_KEY'] = '-----------------'\n",
    "t_credentials['ACCESS_SECRET'] = '-----------------'\n",
    "\n",
    "#load Twitter API credentials\n",
    "consumer_key = t_credentials['CONSUMER_KEY']\n",
    "consumer_secret = t_credentials['CONSUMER_SECRET']\n",
    "access_key = t_credentials['ACCESS_KEY']\n",
    "access_secret = t_credentials['ACCESS_SECRET']\n",
    "\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_key, access_secret)\n",
    "api = tweepy.API(auth,wait_on_rate_limit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nhash_tags = \\'#brexit -filter:retweets\\'\\ntweet_cols = [\\'created_at\\',\\'id\\',\\'screen_name\\',\\'location\\',\\'followers_count\\',\\'friends_count\\',\\'retweeted\\',\\'retweet_count\\',\\n              \\'text\\',\\'tags\\',\\'mentions\\']\\ntweet_df = pd.DataFrame(columns = tweet_cols)\\nfor tweet in tweepy.Cursor(api.search,q=hash_tags, result_type=\\'recent\\', # Example Values: mixed, recent, popular\\n                           lang=\"en\",tweet_mode=\\'extended\\',until=\\'2019-04-30\\',wait_on_rate_limit=True).items(400000):\\n    tags=[]\\n    for i in range(len(tweet.entities[\\'hashtags\\'])):\\n        tags.append(\\'#\\'+tweet.entities[\\'hashtags\\'][i][\\'text\\'].lower())\\n    mentions = []\\n    for i in range(len(tweet.entities[\\'user_mentions\\'])):\\n        mentions.append(\\'@\\'+tweet.entities[\\'user_mentions\\'][i][\\'screen_name\\'])\\n    df = pd.DataFrame([[tweet.created_at,tweet.id,tweet.user.screen_name,tweet.user.location,tweet.user.followers_count,\\n                        tweet.user.friends_count,tweet.retweeted,tweet.retweet_count,tweet.full_text,tags,mentions]],columns = tweet_cols)\\n    tweet_df = tweet_df.append(df)\\n    tweet_df_rows = tweet_df.shape[0]\\n    if(tweet_df_rows%100==0):\\n        print(str(tweet_df_rows)+\\'---\\'+str(df[\\'created_at\\']))\\ntweet_df.reset_index(drop=True,inplace=True)\\ntweet_df = tweet_df.sort_values([\\'created_at\\'],ascending=[False])\\nprint(tweet_df.shape)\\nprint(tweet_df[\\'created_at\\'].min())\\nprint(tweet_df[\\'created_at\\'].max())\\nprint(tweet_df[\\'retweet_count\\'].max())\\ntweet_df.head()\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Tweet data is collected using this cell. \n",
    "#Since the data is already collected and stored in brexit_tweets_april.csv, no need to run this cell.\n",
    "#Just read the data from brexit_tweets_april.csv file which is done below.\n",
    "'''\n",
    "\n",
    "hash_tags = '#brexit -filter:retweets'\n",
    "tweet_cols = ['created_at','id','screen_name','location','followers_count','friends_count','retweeted','retweet_count',\n",
    "              'text','tags','mentions']\n",
    "tweet_df = pd.DataFrame(columns = tweet_cols)\n",
    "for tweet in tweepy.Cursor(api.search,q=hash_tags, result_type='recent', # Example Values: mixed, recent, popular\n",
    "                           lang=\"en\",tweet_mode='extended',until='2019-04-30',wait_on_rate_limit=True).items(400000):\n",
    "    tags=[]\n",
    "    for i in range(len(tweet.entities['hashtags'])):\n",
    "        tags.append('#'+tweet.entities['hashtags'][i]['text'].lower())\n",
    "    mentions = []\n",
    "    for i in range(len(tweet.entities['user_mentions'])):\n",
    "        mentions.append('@'+tweet.entities['user_mentions'][i]['screen_name'])\n",
    "    df = pd.DataFrame([[tweet.created_at,tweet.id,tweet.user.screen_name,tweet.user.location,tweet.user.followers_count,\n",
    "                        tweet.user.friends_count,tweet.retweeted,tweet.retweet_count,tweet.full_text,tags,mentions]],columns = tweet_cols)\n",
    "    tweet_df = tweet_df.append(df)\n",
    "    tweet_df_rows = tweet_df.shape[0]\n",
    "    if(tweet_df_rows%100==0):\n",
    "        print(str(tweet_df_rows)+'---'+str(df['created_at']))\n",
    "tweet_df.reset_index(drop=True,inplace=True)\n",
    "tweet_df = tweet_df.sort_values(['created_at'],ascending=[False])\n",
    "print(tweet_df.shape)\n",
    "print(tweet_df['created_at'].min())\n",
    "print(tweet_df['created_at'].max())\n",
    "print(tweet_df['retweet_count'].max())\n",
    "tweet_df.head()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(324352, 9)\n",
      "2019-04-01 00:00:00\n",
      "2019-04-29 23:59:59\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>screen_name</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>friends_count</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tags</th>\n",
       "      <th>mentions</th>\n",
       "      <th>dummy_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-04-29 23:59:59</td>\n",
       "      <td>user_61373</td>\n",
       "      <td>749</td>\n",
       "      <td>1327</td>\n",
       "      <td>0</td>\n",
       "      <td>WOW - Another Brexit extension - time now unti...</td>\n",
       "      <td>['#brexit', '#brexitclock', '#clock', '#eu', '...</td>\n",
       "      <td>[]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-04-29 23:58:19</td>\n",
       "      <td>user_56917</td>\n",
       "      <td>281</td>\n",
       "      <td>687</td>\n",
       "      <td>0</td>\n",
       "      <td>.@santanderuk I want to report CEO fraud, howe...</td>\n",
       "      <td>['#brexit']</td>\n",
       "      <td>['@santanderuk']</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-04-29 23:56:55</td>\n",
       "      <td>user_72791</td>\n",
       "      <td>381</td>\n",
       "      <td>1895</td>\n",
       "      <td>0</td>\n",
       "      <td>Voting for #brexit. It is very obvious. https:...</td>\n",
       "      <td>['#brexit']</td>\n",
       "      <td>[]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-04-29 23:56:53</td>\n",
       "      <td>user_9686</td>\n",
       "      <td>21</td>\n",
       "      <td>118</td>\n",
       "      <td>0</td>\n",
       "      <td>@LordCFalconer 1. First ref result couldn't ev...</td>\n",
       "      <td>['#brexit', '#peoplesvote']</td>\n",
       "      <td>['@LordCFalconer']</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-04-29 23:56:53</td>\n",
       "      <td>user_42521</td>\n",
       "      <td>19</td>\n",
       "      <td>130</td>\n",
       "      <td>0</td>\n",
       "      <td>#MAGA #BREXIT #GOP \\r\\n\\r\\nMake a difference, ...</td>\n",
       "      <td>['#maga', '#brexit', '#gop']</td>\n",
       "      <td>[]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            created_at screen_name  followers_count  friends_count  \\\n",
       "0  2019-04-29 23:59:59  user_61373              749           1327   \n",
       "1  2019-04-29 23:58:19  user_56917              281            687   \n",
       "2  2019-04-29 23:56:55  user_72791              381           1895   \n",
       "3  2019-04-29 23:56:53   user_9686               21            118   \n",
       "4  2019-04-29 23:56:53  user_42521               19            130   \n",
       "\n",
       "   retweet_count                                               text  \\\n",
       "0              0  WOW - Another Brexit extension - time now unti...   \n",
       "1              0  .@santanderuk I want to report CEO fraud, howe...   \n",
       "2              0  Voting for #brexit. It is very obvious. https:...   \n",
       "3              0  @LordCFalconer 1. First ref result couldn't ev...   \n",
       "4              0  #MAGA #BREXIT #GOP \\r\\n\\r\\nMake a difference, ...   \n",
       "\n",
       "                                                tags            mentions  \\\n",
       "0  ['#brexit', '#brexitclock', '#clock', '#eu', '...                  []   \n",
       "1                                        ['#brexit']    ['@santanderuk']   \n",
       "2                                        ['#brexit']                  []   \n",
       "3                        ['#brexit', '#peoplesvote']  ['@LordCFalconer']   \n",
       "4                       ['#maga', '#brexit', '#gop']                  []   \n",
       "\n",
       "   dummy_count  \n",
       "0            1  \n",
       "1            1  \n",
       "2            1  \n",
       "3            1  \n",
       "4            1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_df = pd.read_csv('Outputs/brexit_tweets_april.csv',lineterminator='\\n')\n",
    "tweet_df['mentions'] = tweet_df['mentions\\r'].str.strip()\n",
    "tweet_df['dummy_count'] = 1\n",
    "tweet_df = tweet_df.drop(['Unnamed: 0','id','location','retweeted','mentions\\r'],axis='columns')\n",
    "\n",
    "#Map the twitter user names into ids\n",
    "tweeters = sorted(list(set(list(tweet_df['screen_name']))))\n",
    "tweeters_id = [('user_'+str(i)) for i in range(len(tweeters))]\n",
    "mapping_dict = {tweeters[i]:tweeters_id[i] for i in range(len(tweeters))}\n",
    "tweet_df['screen_name'] = tweet_df['screen_name'].map(mapping_dict)\n",
    "\n",
    "print(tweet_df.shape)\n",
    "print(tweet_df['created_at'].min())\n",
    "print(tweet_df['created_at'].max())\n",
    "tweet_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99229"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(tweet_df['screen_name']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "99,229 twitter users have originally tweeted about #Brexit in English during the month of April, 2019."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions that calculates sentiment in tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "retweet_threshold = 10  \n",
    "\n",
    "def clean_tweet(tweet):\n",
    "    return ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", \" \", tweet).split())\n",
    "\n",
    "def fill_sentiments(tweet_df):\n",
    "    tweet_df['tweet_sentiment_polarity'] = 0.0\n",
    "    tweet_df['tweet_sentiment_subjectivity'] = 0.0\n",
    "    for index,row in tweet_df.iterrows():\n",
    "        cleaned_tweet = row['text']\n",
    "        s_analysis = TextBlob(cleaned_tweet)\n",
    "        tweet_df.at[index,'tweet_sentiment_polarity'] = s_analysis.sentiment.polarity\n",
    "        tweet_df.at[index,'tweet_sentiment_subjectivity'] = s_analysis.sentiment.subjectivity\n",
    "    return tweet_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Week 1 tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(135507, 11)\n",
      "2019-04-01 00:00:00\n",
      "2019-04-06 23:59:54\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>screen_name</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>friends_count</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tags</th>\n",
       "      <th>mentions</th>\n",
       "      <th>dummy_count</th>\n",
       "      <th>tweet_sentiment_polarity</th>\n",
       "      <th>tweet_sentiment_subjectivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-04-06 23:59:54</td>\n",
       "      <td>user_61373</td>\n",
       "      <td>755</td>\n",
       "      <td>1323</td>\n",
       "      <td>0</td>\n",
       "      <td>If BREXIT is April 12th we have:  5 days, 21 h...</td>\n",
       "      <td>['#brexit', '#brexitclock', '#clock', '#eu', '...</td>\n",
       "      <td>[]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-04-06 23:59:52</td>\n",
       "      <td>user_78016</td>\n",
       "      <td>3264</td>\n",
       "      <td>4850</td>\n",
       "      <td>0</td>\n",
       "      <td>@Two_Penneth Demagogues plying their dismal tr...</td>\n",
       "      <td>['#brexit']</td>\n",
       "      <td>['@Two_Penneth']</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.066667</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-04-06 23:59:49</td>\n",
       "      <td>user_18730</td>\n",
       "      <td>8472</td>\n",
       "      <td>9450</td>\n",
       "      <td>0</td>\n",
       "      <td>What a police state looks like - \\r\\r\\r\\n🇫🇷#Fr...</td>\n",
       "      <td>['#france', '#macronmustgo', '#nobolshevism', ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-04-06 23:59:42</td>\n",
       "      <td>user_30713</td>\n",
       "      <td>142</td>\n",
       "      <td>200</td>\n",
       "      <td>0</td>\n",
       "      <td>I don't know how many words Trump made but the...</td>\n",
       "      <td>['#brexit']</td>\n",
       "      <td>[]</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.055556</td>\n",
       "      <td>0.522222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-04-06 23:59:25</td>\n",
       "      <td>user_89867</td>\n",
       "      <td>2</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>@LauraEmilyBush My statement as the self-procl...</td>\n",
       "      <td>['#germany', '#brexit']</td>\n",
       "      <td>['@LauraEmilyBush']</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.050000</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            created_at screen_name  followers_count  friends_count  \\\n",
       "0  2019-04-06 23:59:54  user_61373              755           1323   \n",
       "1  2019-04-06 23:59:52  user_78016             3264           4850   \n",
       "2  2019-04-06 23:59:49  user_18730             8472           9450   \n",
       "3  2019-04-06 23:59:42  user_30713              142            200   \n",
       "4  2019-04-06 23:59:25  user_89867                2             47   \n",
       "\n",
       "   retweet_count                                               text  \\\n",
       "0              0  If BREXIT is April 12th we have:  5 days, 21 h...   \n",
       "1              0  @Two_Penneth Demagogues plying their dismal tr...   \n",
       "2              0  What a police state looks like - \\r\\r\\r\\n🇫🇷#Fr...   \n",
       "3              0  I don't know how many words Trump made but the...   \n",
       "4              0  @LauraEmilyBush My statement as the self-procl...   \n",
       "\n",
       "                                                tags             mentions  \\\n",
       "0  ['#brexit', '#brexitclock', '#clock', '#eu', '...                   []   \n",
       "1                                        ['#brexit']     ['@Two_Penneth']   \n",
       "2  ['#france', '#macronmustgo', '#nobolshevism', ...                   []   \n",
       "3                                        ['#brexit']                   []   \n",
       "4                            ['#germany', '#brexit']  ['@LauraEmilyBush']   \n",
       "\n",
       "   dummy_count  tweet_sentiment_polarity  tweet_sentiment_subjectivity  \n",
       "0            1                  0.000000                      0.000000  \n",
       "1            1                 -0.066667                      0.500000  \n",
       "2            1                  0.000000                      0.000000  \n",
       "3            1                 -0.055556                      0.522222  \n",
       "4            1                 -0.050000                      0.400000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_df_week1 = tweet_df[tweet_df['created_at']<='2019-04-06 23:59:59'].copy()\n",
    "tweet_df_week1.reset_index(drop=True,inplace=True)\n",
    "tweet_df_week1 = fill_sentiments(tweet_df_week1)\n",
    "print(tweet_df_week1.shape)\n",
    "print(tweet_df_week1['created_at'].min())\n",
    "print(tweet_df_week1['created_at'].max())\n",
    "tweet_df_week1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "-0.71\n",
      "(2700, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>screen_name</th>\n",
       "      <th>total_tweet_count</th>\n",
       "      <th>total_retweet_count</th>\n",
       "      <th>max_followers_count</th>\n",
       "      <th>max_friends_count</th>\n",
       "      <th>agg_sentiment_polarity</th>\n",
       "      <th>agg_sentiment_subjectivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2695</th>\n",
       "      <td>user_98820</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>522</td>\n",
       "      <td>254</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2696</th>\n",
       "      <td>user_98925</td>\n",
       "      <td>24</td>\n",
       "      <td>249</td>\n",
       "      <td>9042</td>\n",
       "      <td>8052</td>\n",
       "      <td>-0.061127</td>\n",
       "      <td>0.446520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2697</th>\n",
       "      <td>user_99092</td>\n",
       "      <td>16</td>\n",
       "      <td>32</td>\n",
       "      <td>13232</td>\n",
       "      <td>204</td>\n",
       "      <td>-0.082292</td>\n",
       "      <td>0.380729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2698</th>\n",
       "      <td>user_9917</td>\n",
       "      <td>4</td>\n",
       "      <td>19</td>\n",
       "      <td>33314</td>\n",
       "      <td>752</td>\n",
       "      <td>0.108036</td>\n",
       "      <td>0.391369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2699</th>\n",
       "      <td>user_9961</td>\n",
       "      <td>17</td>\n",
       "      <td>122</td>\n",
       "      <td>3636723</td>\n",
       "      <td>485</td>\n",
       "      <td>0.033783</td>\n",
       "      <td>0.244404</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     screen_name  total_tweet_count  total_retweet_count  max_followers_count  \\\n",
       "2695  user_98820                  1                   12                  522   \n",
       "2696  user_98925                 24                  249                 9042   \n",
       "2697  user_99092                 16                   32                13232   \n",
       "2698   user_9917                  4                   19                33314   \n",
       "2699   user_9961                 17                  122              3636723   \n",
       "\n",
       "      max_friends_count  agg_sentiment_polarity  agg_sentiment_subjectivity  \n",
       "2695                254                0.000000                    0.000000  \n",
       "2696               8052               -0.061127                    0.446520  \n",
       "2697                204               -0.082292                    0.380729  \n",
       "2698                752                0.108036                    0.391369  \n",
       "2699                485                0.033783                    0.244404  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retweets_df_week1 = tweet_df_week1[['screen_name','retweet_count']].groupby('screen_name').sum()\n",
    "followers_df_week1 = tweet_df_week1[['screen_name','followers_count']].groupby('screen_name').max() #Max of the week\n",
    "friends_df_week1 = tweet_df_week1[['screen_name','friends_count']].groupby('screen_name').max()  #Max of the week\n",
    "sentiment_polarity_df_week1 = tweet_df_week1[['screen_name','tweet_sentiment_polarity']].groupby('screen_name').sum()\n",
    "sentiment_subjectivity_df_week1 = tweet_df_week1[['screen_name','tweet_sentiment_subjectivity']].groupby('screen_name').sum()\n",
    "tweet_count_df_week1 = tweet_df_week1[['screen_name','dummy_count']].groupby('screen_name').sum()\n",
    "\n",
    "week1_stats_df = pd.concat([tweet_count_df_week1,retweets_df_week1,followers_df_week1,friends_df_week1,\n",
    "                            sentiment_polarity_df_week1,sentiment_subjectivity_df_week1],axis='columns')\n",
    "week1_stats_df['screen_name'] = week1_stats_df.index\n",
    "week1_stats_df = week1_stats_df[['screen_name','dummy_count','retweet_count','followers_count','friends_count',\n",
    "                                 'tweet_sentiment_polarity','tweet_sentiment_subjectivity']]\n",
    "week1_stats_df = week1_stats_df.rename(columns={\"retweet_count\":\"total_retweet_count\",\"followers_count\":\"max_followers_count\",\n",
    "                                                \"friends_count\":\"max_friends_count\",\"dummy_count\":\"total_tweet_count\",\n",
    "                                                \"tweet_sentiment_polarity\":\"agg_sentiment_polarity\",\n",
    "                                                \"tweet_sentiment_subjectivity\":\"agg_sentiment_subjectivity\"})\n",
    "week1_stats_df = week1_stats_df[week1_stats_df['total_retweet_count']>=retweet_threshold]\n",
    "week1_stats_df['agg_sentiment_polarity'] = week1_stats_df['agg_sentiment_polarity']/week1_stats_df['total_tweet_count']\n",
    "week1_stats_df['agg_sentiment_subjectivity'] = week1_stats_df['agg_sentiment_subjectivity']/week1_stats_df['total_tweet_count']\n",
    "week1_stats_df.reset_index(drop=True,inplace=True)\n",
    "print(week1_stats_df['agg_sentiment_polarity'].max())\n",
    "print(week1_stats_df['agg_sentiment_polarity'].min())\n",
    "print(week1_stats_df.shape)\n",
    "week1_stats_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Week 2 tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100633, 11)\n",
      "2019-04-07 00:00:03\n",
      "2019-04-13 23:59:28\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>screen_name</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>friends_count</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tags</th>\n",
       "      <th>mentions</th>\n",
       "      <th>dummy_count</th>\n",
       "      <th>tweet_sentiment_polarity</th>\n",
       "      <th>tweet_sentiment_subjectivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-04-13 23:59:28</td>\n",
       "      <td>user_36737</td>\n",
       "      <td>28</td>\n",
       "      <td>165</td>\n",
       "      <td>0</td>\n",
       "      <td>@Nigel_Farage @brexitparty_uk @Nigel_Farage So...</td>\n",
       "      <td>['#greatergood', '#brexit']</td>\n",
       "      <td>['@Nigel_Farage', '@brexitparty_uk', '@Nigel_F...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.101786</td>\n",
       "      <td>0.392857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-04-13 23:58:37</td>\n",
       "      <td>user_4214</td>\n",
       "      <td>31</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>@SKinnock You are just like your dad - a panty...</td>\n",
       "      <td>['#labour', '#brexit']</td>\n",
       "      <td>['@SKinnock']</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.250000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-04-13 23:58:17</td>\n",
       "      <td>user_36737</td>\n",
       "      <td>28</td>\n",
       "      <td>165</td>\n",
       "      <td>0</td>\n",
       "      <td>@Nigel_Farage Sorry to hear you won't be on th...</td>\n",
       "      <td>['#greatergood', '#brexit']</td>\n",
       "      <td>['@Nigel_Farage']</td>\n",
       "      <td>1</td>\n",
       "      <td>0.101786</td>\n",
       "      <td>0.392857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-04-13 23:57:28</td>\n",
       "      <td>user_56063</td>\n",
       "      <td>402</td>\n",
       "      <td>1738</td>\n",
       "      <td>0</td>\n",
       "      <td>Lets keep this fresh folks, please retweet \\r\\...</td>\n",
       "      <td>['#brexit', '#brextension']</td>\n",
       "      <td>[]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-04-13 23:57:02</td>\n",
       "      <td>user_31716</td>\n",
       "      <td>435</td>\n",
       "      <td>857</td>\n",
       "      <td>0</td>\n",
       "      <td>Petition: Halt #Brexit For A Public Inquiry ht...</td>\n",
       "      <td>['#brexit']</td>\n",
       "      <td>[]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.066667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            created_at screen_name  followers_count  friends_count  \\\n",
       "0  2019-04-13 23:59:28  user_36737               28            165   \n",
       "1  2019-04-13 23:58:37   user_4214               31             27   \n",
       "2  2019-04-13 23:58:17  user_36737               28            165   \n",
       "3  2019-04-13 23:57:28  user_56063              402           1738   \n",
       "4  2019-04-13 23:57:02  user_31716              435            857   \n",
       "\n",
       "   retweet_count                                               text  \\\n",
       "0              0  @Nigel_Farage @brexitparty_uk @Nigel_Farage So...   \n",
       "1              0  @SKinnock You are just like your dad - a panty...   \n",
       "2              0  @Nigel_Farage Sorry to hear you won't be on th...   \n",
       "3              0  Lets keep this fresh folks, please retweet \\r\\...   \n",
       "4              0  Petition: Halt #Brexit For A Public Inquiry ht...   \n",
       "\n",
       "                          tags  \\\n",
       "0  ['#greatergood', '#brexit']   \n",
       "1       ['#labour', '#brexit']   \n",
       "2  ['#greatergood', '#brexit']   \n",
       "3  ['#brexit', '#brextension']   \n",
       "4                  ['#brexit']   \n",
       "\n",
       "                                            mentions  dummy_count  \\\n",
       "0  ['@Nigel_Farage', '@brexitparty_uk', '@Nigel_F...            1   \n",
       "1                                      ['@SKinnock']            1   \n",
       "2                                  ['@Nigel_Farage']            1   \n",
       "3                                                 []            1   \n",
       "4                                                 []            1   \n",
       "\n",
       "   tweet_sentiment_polarity  tweet_sentiment_subjectivity  \n",
       "0                  0.101786                      0.392857  \n",
       "1                 -0.250000                      0.000000  \n",
       "2                  0.101786                      0.392857  \n",
       "3                  0.300000                      0.500000  \n",
       "4                  0.000000                      0.066667  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_df_week2 = tweet_df[(tweet_df['created_at']>'2019-04-06 23:59:59') & (tweet_df['created_at']<='2019-04-13 23:59:59')].copy()\n",
    "tweet_df_week2.reset_index(drop=True,inplace=True)\n",
    "tweet_df_week2 = fill_sentiments(tweet_df_week2)\n",
    "print(tweet_df_week2.shape)\n",
    "print(tweet_df_week2['created_at'].min())\n",
    "print(tweet_df_week2['created_at'].max())\n",
    "tweet_df_week2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "-1.0\n",
      "(2097, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>screen_name</th>\n",
       "      <th>total_tweet_count</th>\n",
       "      <th>total_retweet_count</th>\n",
       "      <th>max_followers_count</th>\n",
       "      <th>max_friends_count</th>\n",
       "      <th>agg_sentiment_polarity</th>\n",
       "      <th>agg_sentiment_subjectivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2092</th>\n",
       "      <td>user_9960</td>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "      <td>71</td>\n",
       "      <td>184</td>\n",
       "      <td>0.066111</td>\n",
       "      <td>0.378889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2093</th>\n",
       "      <td>user_9961</td>\n",
       "      <td>5</td>\n",
       "      <td>42</td>\n",
       "      <td>3657779</td>\n",
       "      <td>487</td>\n",
       "      <td>-0.012667</td>\n",
       "      <td>0.165333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2094</th>\n",
       "      <td>user_9964</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>744963</td>\n",
       "      <td>203</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2095</th>\n",
       "      <td>user_9966</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>12634</td>\n",
       "      <td>918</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2096</th>\n",
       "      <td>user_9970</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>-0.041667</td>\n",
       "      <td>0.291667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     screen_name  total_tweet_count  total_retweet_count  max_followers_count  \\\n",
       "2092   user_9960                 12                   14                   71   \n",
       "2093   user_9961                  5                   42              3657779   \n",
       "2094   user_9964                  3                   14               744963   \n",
       "2095   user_9966                  1                   11                12634   \n",
       "2096   user_9970                  3                   10                    3   \n",
       "\n",
       "      max_friends_count  agg_sentiment_polarity  agg_sentiment_subjectivity  \n",
       "2092                184                0.066111                    0.378889  \n",
       "2093                487               -0.012667                    0.165333  \n",
       "2094                203                0.166667                    0.166667  \n",
       "2095                918                0.000000                    0.000000  \n",
       "2096                 17               -0.041667                    0.291667  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retweets_df_week2 = tweet_df_week2[['screen_name','retweet_count']].groupby('screen_name').sum()\n",
    "followers_df_week2 = tweet_df_week2[['screen_name','followers_count']].groupby('screen_name').max() #Max of the week\n",
    "friends_df_week2 = tweet_df_week2[['screen_name','friends_count']].groupby('screen_name').max()  #Max of the week\n",
    "sentiment_polarity_df_week2 = tweet_df_week2[['screen_name','tweet_sentiment_polarity']].groupby('screen_name').sum()\n",
    "sentiment_subjectivity_df_week2 = tweet_df_week2[['screen_name','tweet_sentiment_subjectivity']].groupby('screen_name').sum()\n",
    "tweet_count_df_week2 = tweet_df_week2[['screen_name','dummy_count']].groupby('screen_name').sum()\n",
    "\n",
    "week2_stats_df = pd.concat([tweet_count_df_week2,retweets_df_week2,followers_df_week2,friends_df_week2,\n",
    "                            sentiment_polarity_df_week2,sentiment_subjectivity_df_week2],axis='columns')\n",
    "week2_stats_df['screen_name'] = week2_stats_df.index\n",
    "week2_stats_df = week2_stats_df[['screen_name','dummy_count','retweet_count','followers_count','friends_count',\n",
    "                                 'tweet_sentiment_polarity','tweet_sentiment_subjectivity']]\n",
    "week2_stats_df = week2_stats_df.rename(columns={\"retweet_count\":\"total_retweet_count\",\"followers_count\":\"max_followers_count\",\n",
    "                                                \"friends_count\":\"max_friends_count\",\"dummy_count\":\"total_tweet_count\",\n",
    "                                                \"tweet_sentiment_polarity\":\"agg_sentiment_polarity\",\n",
    "                                                \"tweet_sentiment_subjectivity\":\"agg_sentiment_subjectivity\"})\n",
    "week2_stats_df = week2_stats_df[week2_stats_df['total_retweet_count']>=retweet_threshold]\n",
    "week2_stats_df['agg_sentiment_polarity'] = week2_stats_df['agg_sentiment_polarity']/week2_stats_df['total_tweet_count']\n",
    "week2_stats_df['agg_sentiment_subjectivity'] = week2_stats_df['agg_sentiment_subjectivity']/week2_stats_df['total_tweet_count']\n",
    "week2_stats_df.reset_index(drop=True,inplace=True)\n",
    "print(week2_stats_df['agg_sentiment_polarity'].max())\n",
    "print(week2_stats_df['agg_sentiment_polarity'].min())\n",
    "print(week2_stats_df.shape)\n",
    "week2_stats_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Week 3 tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42048, 11)\n",
      "2019-04-14 00:00:00\n",
      "2019-04-20 23:59:53\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>screen_name</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>friends_count</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tags</th>\n",
       "      <th>mentions</th>\n",
       "      <th>dummy_count</th>\n",
       "      <th>tweet_sentiment_polarity</th>\n",
       "      <th>tweet_sentiment_subjectivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-04-20 23:59:53</td>\n",
       "      <td>user_61373</td>\n",
       "      <td>751</td>\n",
       "      <td>1329</td>\n",
       "      <td>0</td>\n",
       "      <td>WOW - Another Brexit extension - time now unti...</td>\n",
       "      <td>['#brexit', '#brexitclock', '#clock', '#eu', '...</td>\n",
       "      <td>[]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.100</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-04-20 23:59:16</td>\n",
       "      <td>user_42372</td>\n",
       "      <td>1522</td>\n",
       "      <td>3686</td>\n",
       "      <td>1</td>\n",
       "      <td>I don't think he's feeling it...\\r\\r\\r\\n\\r\\r\\r...</td>\n",
       "      <td>['#ico', '#ethereum', '#crypto', '#crowdfundin...</td>\n",
       "      <td>[]</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.025</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-04-20 23:58:39</td>\n",
       "      <td>user_3678</td>\n",
       "      <td>23602</td>\n",
       "      <td>22764</td>\n",
       "      <td>20</td>\n",
       "      <td>#Remain voting 4 Dummies  (Like me) \\r\\r\\r\\n1....</td>\n",
       "      <td>['#remain', '#brexit']</td>\n",
       "      <td>[]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-04-20 23:58:24</td>\n",
       "      <td>user_7535</td>\n",
       "      <td>90</td>\n",
       "      <td>195</td>\n",
       "      <td>7</td>\n",
       "      <td>#brexitparty #brexit #BrexitBetrayal #northeas...</td>\n",
       "      <td>['#brexitparty', '#brexit', '#brexitbetrayal',...</td>\n",
       "      <td>[]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-04-20 23:58:10</td>\n",
       "      <td>user_12992</td>\n",
       "      <td>308</td>\n",
       "      <td>691</td>\n",
       "      <td>0</td>\n",
       "      <td>@highwaysagency @theresa_may Fiddlesticks to #...</td>\n",
       "      <td>['#brexit']</td>\n",
       "      <td>['@highwaysagency', '@theresa_may']</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            created_at screen_name  followers_count  friends_count  \\\n",
       "0  2019-04-20 23:59:53  user_61373              751           1329   \n",
       "1  2019-04-20 23:59:16  user_42372             1522           3686   \n",
       "2  2019-04-20 23:58:39   user_3678            23602          22764   \n",
       "3  2019-04-20 23:58:24   user_7535               90            195   \n",
       "4  2019-04-20 23:58:10  user_12992              308            691   \n",
       "\n",
       "   retweet_count                                               text  \\\n",
       "0              0  WOW - Another Brexit extension - time now unti...   \n",
       "1              1  I don't think he's feeling it...\\r\\r\\r\\n\\r\\r\\r...   \n",
       "2             20  #Remain voting 4 Dummies  (Like me) \\r\\r\\r\\n1....   \n",
       "3              7  #brexitparty #brexit #BrexitBetrayal #northeas...   \n",
       "4              0  @highwaysagency @theresa_may Fiddlesticks to #...   \n",
       "\n",
       "                                                tags  \\\n",
       "0  ['#brexit', '#brexitclock', '#clock', '#eu', '...   \n",
       "1  ['#ico', '#ethereum', '#crypto', '#crowdfundin...   \n",
       "2                             ['#remain', '#brexit']   \n",
       "3  ['#brexitparty', '#brexit', '#brexitbetrayal',...   \n",
       "4                                        ['#brexit']   \n",
       "\n",
       "                              mentions  dummy_count  tweet_sentiment_polarity  \\\n",
       "0                                   []            1                     0.100   \n",
       "1                                   []            1                    -0.025   \n",
       "2                                   []            1                     0.000   \n",
       "3                                   []            1                     0.000   \n",
       "4  ['@highwaysagency', '@theresa_may']            1                     0.000   \n",
       "\n",
       "   tweet_sentiment_subjectivity  \n",
       "0                           1.0  \n",
       "1                           0.7  \n",
       "2                           0.0  \n",
       "3                           0.0  \n",
       "4                           0.0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_df_week3 = tweet_df[(tweet_df['created_at']>'2019-04-13 23:59:59') & (tweet_df['created_at']<='2019-04-20 23:59:59')].copy()\n",
    "tweet_df_week3.reset_index(drop=True,inplace=True)\n",
    "tweet_df_week3 = fill_sentiments(tweet_df_week3)\n",
    "print(tweet_df_week3.shape)\n",
    "print(tweet_df_week3['created_at'].min())\n",
    "print(tweet_df_week3['created_at'].max())\n",
    "tweet_df_week3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "-1.0\n",
      "(1037, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>screen_name</th>\n",
       "      <th>total_tweet_count</th>\n",
       "      <th>total_retweet_count</th>\n",
       "      <th>max_followers_count</th>\n",
       "      <th>max_friends_count</th>\n",
       "      <th>agg_sentiment_polarity</th>\n",
       "      <th>agg_sentiment_subjectivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1032</th>\n",
       "      <td>user_99088</td>\n",
       "      <td>1</td>\n",
       "      <td>159</td>\n",
       "      <td>15723</td>\n",
       "      <td>197</td>\n",
       "      <td>0.018750</td>\n",
       "      <td>0.056250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1033</th>\n",
       "      <td>user_99092</td>\n",
       "      <td>19</td>\n",
       "      <td>74</td>\n",
       "      <td>13264</td>\n",
       "      <td>205</td>\n",
       "      <td>0.171053</td>\n",
       "      <td>0.493421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1034</th>\n",
       "      <td>user_9919</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>108</td>\n",
       "      <td>316</td>\n",
       "      <td>-0.025000</td>\n",
       "      <td>0.419444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1035</th>\n",
       "      <td>user_9944</td>\n",
       "      <td>63</td>\n",
       "      <td>26</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.005518</td>\n",
       "      <td>0.040665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1036</th>\n",
       "      <td>user_9961</td>\n",
       "      <td>6</td>\n",
       "      <td>109</td>\n",
       "      <td>3674083</td>\n",
       "      <td>487</td>\n",
       "      <td>-0.095859</td>\n",
       "      <td>0.215934</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     screen_name  total_tweet_count  total_retweet_count  max_followers_count  \\\n",
       "1032  user_99088                  1                  159                15723   \n",
       "1033  user_99092                 19                   74                13264   \n",
       "1034   user_9919                  3                   15                  108   \n",
       "1035   user_9944                 63                   26                    7   \n",
       "1036   user_9961                  6                  109              3674083   \n",
       "\n",
       "      max_friends_count  agg_sentiment_polarity  agg_sentiment_subjectivity  \n",
       "1032                197                0.018750                    0.056250  \n",
       "1033                205                0.171053                    0.493421  \n",
       "1034                316               -0.025000                    0.419444  \n",
       "1035                  0               -0.005518                    0.040665  \n",
       "1036                487               -0.095859                    0.215934  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retweets_df_week3 = tweet_df_week3[['screen_name','retweet_count']].groupby('screen_name').sum()\n",
    "followers_df_week3 = tweet_df_week3[['screen_name','followers_count']].groupby('screen_name').max() #Max of the week\n",
    "friends_df_week3 = tweet_df_week3[['screen_name','friends_count']].groupby('screen_name').max()  #Max of the week\n",
    "sentiment_polarity_df_week3 = tweet_df_week3[['screen_name','tweet_sentiment_polarity']].groupby('screen_name').sum()\n",
    "sentiment_subjectivity_df_week3 = tweet_df_week3[['screen_name','tweet_sentiment_subjectivity']].groupby('screen_name').sum()\n",
    "tweet_count_df_week3 = tweet_df_week3[['screen_name','dummy_count']].groupby('screen_name').sum()\n",
    "\n",
    "week3_stats_df = pd.concat([tweet_count_df_week3,retweets_df_week3,followers_df_week3,friends_df_week3,\n",
    "                            sentiment_polarity_df_week3,sentiment_subjectivity_df_week3],axis='columns')\n",
    "week3_stats_df['screen_name'] = week3_stats_df.index\n",
    "week3_stats_df = week3_stats_df[['screen_name','dummy_count','retweet_count','followers_count','friends_count',\n",
    "                                 'tweet_sentiment_polarity','tweet_sentiment_subjectivity']]\n",
    "week3_stats_df = week3_stats_df.rename(columns={\"retweet_count\":\"total_retweet_count\",\"followers_count\":\"max_followers_count\",\n",
    "                                                \"friends_count\":\"max_friends_count\",\"dummy_count\":\"total_tweet_count\",\n",
    "                                                \"tweet_sentiment_polarity\":\"agg_sentiment_polarity\",\n",
    "                                                \"tweet_sentiment_subjectivity\":\"agg_sentiment_subjectivity\"})\n",
    "week3_stats_df = week3_stats_df[week3_stats_df['total_retweet_count']>=retweet_threshold]\n",
    "week3_stats_df['agg_sentiment_polarity'] = week3_stats_df['agg_sentiment_polarity']/week3_stats_df['total_tweet_count']\n",
    "week3_stats_df['agg_sentiment_subjectivity'] = week3_stats_df['agg_sentiment_subjectivity']/week3_stats_df['total_tweet_count']\n",
    "week3_stats_df.reset_index(drop=True,inplace=True)\n",
    "print(week3_stats_df['agg_sentiment_polarity'].max())\n",
    "print(week3_stats_df['agg_sentiment_polarity'].min())\n",
    "print(week3_stats_df.shape)\n",
    "week3_stats_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Week 4 tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32613, 11)\n",
      "2019-04-24 00:00:10\n",
      "2019-04-29 23:59:59\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>screen_name</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>friends_count</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tags</th>\n",
       "      <th>mentions</th>\n",
       "      <th>dummy_count</th>\n",
       "      <th>tweet_sentiment_polarity</th>\n",
       "      <th>tweet_sentiment_subjectivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-04-29 23:59:59</td>\n",
       "      <td>user_61373</td>\n",
       "      <td>749</td>\n",
       "      <td>1327</td>\n",
       "      <td>0</td>\n",
       "      <td>WOW - Another Brexit extension - time now unti...</td>\n",
       "      <td>['#brexit', '#brexitclock', '#clock', '#eu', '...</td>\n",
       "      <td>[]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-04-29 23:58:19</td>\n",
       "      <td>user_56917</td>\n",
       "      <td>281</td>\n",
       "      <td>687</td>\n",
       "      <td>0</td>\n",
       "      <td>.@santanderuk I want to report CEO fraud, howe...</td>\n",
       "      <td>['#brexit']</td>\n",
       "      <td>['@santanderuk']</td>\n",
       "      <td>1</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.275000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-04-29 23:56:55</td>\n",
       "      <td>user_72791</td>\n",
       "      <td>381</td>\n",
       "      <td>1895</td>\n",
       "      <td>0</td>\n",
       "      <td>Voting for #brexit. It is very obvious. https:...</td>\n",
       "      <td>['#brexit']</td>\n",
       "      <td>[]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-04-29 23:56:53</td>\n",
       "      <td>user_9686</td>\n",
       "      <td>21</td>\n",
       "      <td>118</td>\n",
       "      <td>0</td>\n",
       "      <td>@LordCFalconer 1. First ref result couldn't ev...</td>\n",
       "      <td>['#brexit', '#peoplesvote']</td>\n",
       "      <td>['@LordCFalconer']</td>\n",
       "      <td>1</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.377778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-04-29 23:56:53</td>\n",
       "      <td>user_42521</td>\n",
       "      <td>19</td>\n",
       "      <td>130</td>\n",
       "      <td>0</td>\n",
       "      <td>#MAGA #BREXIT #GOP \\r\\n\\r\\nMake a difference, ...</td>\n",
       "      <td>['#maga', '#brexit', '#gop']</td>\n",
       "      <td>[]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            created_at screen_name  followers_count  friends_count  \\\n",
       "0  2019-04-29 23:59:59  user_61373              749           1327   \n",
       "1  2019-04-29 23:58:19  user_56917              281            687   \n",
       "2  2019-04-29 23:56:55  user_72791              381           1895   \n",
       "3  2019-04-29 23:56:53   user_9686               21            118   \n",
       "4  2019-04-29 23:56:53  user_42521               19            130   \n",
       "\n",
       "   retweet_count                                               text  \\\n",
       "0              0  WOW - Another Brexit extension - time now unti...   \n",
       "1              0  .@santanderuk I want to report CEO fraud, howe...   \n",
       "2              0  Voting for #brexit. It is very obvious. https:...   \n",
       "3              0  @LordCFalconer 1. First ref result couldn't ev...   \n",
       "4              0  #MAGA #BREXIT #GOP \\r\\n\\r\\nMake a difference, ...   \n",
       "\n",
       "                                                tags            mentions  \\\n",
       "0  ['#brexit', '#brexitclock', '#clock', '#eu', '...                  []   \n",
       "1                                        ['#brexit']    ['@santanderuk']   \n",
       "2                                        ['#brexit']                  []   \n",
       "3                        ['#brexit', '#peoplesvote']  ['@LordCFalconer']   \n",
       "4                       ['#maga', '#brexit', '#gop']                  []   \n",
       "\n",
       "   dummy_count  tweet_sentiment_polarity  tweet_sentiment_subjectivity  \n",
       "0            1                  0.100000                      1.000000  \n",
       "1            1                  0.100000                      0.275000  \n",
       "2            1                  0.000000                      0.650000  \n",
       "3            1                  0.083333                      0.377778  \n",
       "4            1                  0.000000                      0.000000  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_df_week4 = tweet_df[tweet_df['created_at']>'2019-04-23 23:59:59'].copy()\n",
    "tweet_df_week4.reset_index(drop=True,inplace=True)\n",
    "tweet_df_week4 = fill_sentiments(tweet_df_week4)\n",
    "print(tweet_df_week4.shape)\n",
    "print(tweet_df_week4['created_at'].min())\n",
    "print(tweet_df_week4['created_at'].max())\n",
    "tweet_df_week4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "-0.8\n",
      "(915, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>screen_name</th>\n",
       "      <th>total_tweet_count</th>\n",
       "      <th>total_retweet_count</th>\n",
       "      <th>max_followers_count</th>\n",
       "      <th>max_friends_count</th>\n",
       "      <th>agg_sentiment_polarity</th>\n",
       "      <th>agg_sentiment_subjectivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>910</th>\n",
       "      <td>user_98925</td>\n",
       "      <td>3</td>\n",
       "      <td>32</td>\n",
       "      <td>9040</td>\n",
       "      <td>8129</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.296296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>911</th>\n",
       "      <td>user_98978</td>\n",
       "      <td>1</td>\n",
       "      <td>578</td>\n",
       "      <td>95838</td>\n",
       "      <td>492</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>912</th>\n",
       "      <td>user_9944</td>\n",
       "      <td>35</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.012517</td>\n",
       "      <td>0.040272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>913</th>\n",
       "      <td>user_9954</td>\n",
       "      <td>24</td>\n",
       "      <td>19</td>\n",
       "      <td>11520</td>\n",
       "      <td>2835</td>\n",
       "      <td>0.020731</td>\n",
       "      <td>0.346759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>914</th>\n",
       "      <td>user_9961</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>3711821</td>\n",
       "      <td>487</td>\n",
       "      <td>0.075000</td>\n",
       "      <td>0.450000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    screen_name  total_tweet_count  total_retweet_count  max_followers_count  \\\n",
       "910  user_98925                  3                   32                 9040   \n",
       "911  user_98978                  1                  578                95838   \n",
       "912   user_9944                 35                   13                    7   \n",
       "913   user_9954                 24                   19                11520   \n",
       "914   user_9961                  2                   13              3711821   \n",
       "\n",
       "     max_friends_count  agg_sentiment_polarity  agg_sentiment_subjectivity  \n",
       "910               8129                0.166667                    0.296296  \n",
       "911                492                0.000000                    0.000000  \n",
       "912                  0               -0.012517                    0.040272  \n",
       "913               2835                0.020731                    0.346759  \n",
       "914                487                0.075000                    0.450000  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retweets_df_week4 = tweet_df_week4[['screen_name','retweet_count']].groupby('screen_name').sum()\n",
    "followers_df_week4 = tweet_df_week4[['screen_name','followers_count']].groupby('screen_name').max() #Max of the week\n",
    "friends_df_week4 = tweet_df_week4[['screen_name','friends_count']].groupby('screen_name').max()  #Max of the week\n",
    "sentiment_polarity_df_week4 = tweet_df_week4[['screen_name','tweet_sentiment_polarity']].groupby('screen_name').sum()\n",
    "sentiment_subjectivity_df_week4 = tweet_df_week4[['screen_name','tweet_sentiment_subjectivity']].groupby('screen_name').sum()\n",
    "tweet_count_df_week4 = tweet_df_week4[['screen_name','dummy_count']].groupby('screen_name').sum()\n",
    "\n",
    "week4_stats_df = pd.concat([tweet_count_df_week4,retweets_df_week4,followers_df_week4,friends_df_week4,\n",
    "                            sentiment_polarity_df_week4,sentiment_subjectivity_df_week4],axis='columns')\n",
    "week4_stats_df['screen_name'] = week4_stats_df.index\n",
    "week4_stats_df = week4_stats_df[['screen_name','dummy_count','retweet_count','followers_count','friends_count',\n",
    "                                 'tweet_sentiment_polarity','tweet_sentiment_subjectivity']]\n",
    "week4_stats_df = week4_stats_df.rename(columns={\"retweet_count\":\"total_retweet_count\",\"followers_count\":\"max_followers_count\",\n",
    "                                                \"friends_count\":\"max_friends_count\",\"dummy_count\":\"total_tweet_count\",\n",
    "                                                \"tweet_sentiment_polarity\":\"agg_sentiment_polarity\",\n",
    "                                                \"tweet_sentiment_subjectivity\":\"agg_sentiment_subjectivity\"})\n",
    "week4_stats_df = week4_stats_df[week4_stats_df['total_retweet_count']>=retweet_threshold]\n",
    "week4_stats_df['agg_sentiment_polarity'] = week4_stats_df['agg_sentiment_polarity']/week4_stats_df['total_tweet_count']\n",
    "week4_stats_df['agg_sentiment_subjectivity'] = week4_stats_df['agg_sentiment_subjectivity']/week4_stats_df['total_tweet_count']\n",
    "week4_stats_df.reset_index(drop=True,inplace=True)\n",
    "print(week4_stats_df['agg_sentiment_polarity'].max())\n",
    "print(week4_stats_df['agg_sentiment_polarity'].min())\n",
    "print(week4_stats_df.shape)\n",
    "week4_stats_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check how many people have tweeted #Brexit for each week of April"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of #brexit (en) tweeters in week 1 is: 57271\n",
      "Number of #brexit (en) tweeters in week 2 is: 43266\n",
      "Number of #brexit (en) tweeters in week 3 is: 19234\n",
      "Number of #brexit (en) tweeters in week 4 is: 14442\n",
      "Number of common #brexit (en) tweeters for all weeks is: 3427\n"
     ]
    }
   ],
   "source": [
    "#Here don't take into account of the retweet_threshold\n",
    "week1_tweeters = set(tweet_df_week1['screen_name'])\n",
    "print(\"Number of #brexit (en) tweeters in week 1 is: \" + str(len(week1_tweeters)))\n",
    "week2_tweeters = set(tweet_df_week2['screen_name'])\n",
    "print(\"Number of #brexit (en) tweeters in week 2 is: \" + str(len(week2_tweeters)))\n",
    "week3_tweeters = set(tweet_df_week3['screen_name'])\n",
    "print(\"Number of #brexit (en) tweeters in week 3 is: \" + str(len(week3_tweeters)))\n",
    "week4_tweeters = set(tweet_df_week4['screen_name'])\n",
    "print(\"Number of #brexit (en) tweeters in week 4 is: \" + str(len(week4_tweeters)))\n",
    "\n",
    "all_week_tweeters = week1_tweeters & week2_tweeters & week3_tweeters & week4_tweeters\n",
    "print(\"Number of common #brexit (en) tweeters for all weeks is: \" + str(len(all_week_tweeters)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Screen only the most popular twitter users whose aggregate retweets for the week > retweet_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of #brexit (en + retweet_threshold) tweeters in week 1 is: 2700\n",
      "Number of #brexit (en + retweet_threshold) tweeters in week 2 is: 2097\n",
      "Number of #brexit (en + retweet_threshold) tweeters in week 3 is: 1037\n",
      "Number of #brexit (en + retweet_threshold) tweeters in week 4 is: 915\n",
      "Number of common #brexit (en + retweet_threshold) tweeters for all weeks is: 240\n"
     ]
    }
   ],
   "source": [
    "week1_popular_tweeters = set(week1_stats_df['screen_name'])\n",
    "print(\"Number of #brexit (en + retweet_threshold) tweeters in week 1 is: \" + str(len(week1_popular_tweeters)))\n",
    "week2_popular_tweeters = set(week2_stats_df['screen_name'])\n",
    "print(\"Number of #brexit (en + retweet_threshold) tweeters in week 2 is: \" + str(len(week2_popular_tweeters)))\n",
    "week3_popular_tweeters = set(week3_stats_df['screen_name'])\n",
    "print(\"Number of #brexit (en + retweet_threshold) tweeters in week 3 is: \" + str(len(week3_popular_tweeters)))\n",
    "week4_popular_tweeters = set(week4_stats_df['screen_name'])\n",
    "print(\"Number of #brexit (en + retweet_threshold) tweeters in week 4 is: \" + str(len(week4_popular_tweeters)))\n",
    "\n",
    "all_week_popular_tweeters = week1_popular_tweeters & week2_popular_tweeters & week3_popular_tweeters & week4_popular_tweeters\n",
    "print(\"Number of common #brexit (en + retweet_threshold) tweeters for all weeks is: \" + str(len(all_week_popular_tweeters)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding edges in the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28680 pairings\n"
     ]
    }
   ],
   "source": [
    "nodes = list(all_week_popular_tweeters)\n",
    "def create_pairings(source):\n",
    "        result = []\n",
    "        for p1 in range(len(source)):\n",
    "                for p2 in range(p1+1,len(source)):\n",
    "                        result.append([source[p1],source[p2]])\n",
    "        return result\n",
    "\n",
    "pairings = create_pairings(nodes)\n",
    "print(\"%d pairings\" % len(pairings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28680, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_screen_name</th>\n",
       "      <th>destination_screen_name</th>\n",
       "      <th>has_mutual_following</th>\n",
       "      <th>source_follow_dest</th>\n",
       "      <th>dest_follow_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>user_77516</td>\n",
       "      <td>user_68504</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>user_77516</td>\n",
       "      <td>user_82690</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>user_77516</td>\n",
       "      <td>user_69243</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>user_77516</td>\n",
       "      <td>user_51280</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>user_77516</td>\n",
       "      <td>user_86664</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  source_screen_name destination_screen_name  has_mutual_following  \\\n",
       "0         user_77516              user_68504                 False   \n",
       "1         user_77516              user_82690                 False   \n",
       "2         user_77516              user_69243                 False   \n",
       "3         user_77516              user_51280                 False   \n",
       "4         user_77516              user_86664                 False   \n",
       "\n",
       "   source_follow_dest  dest_follow_source  \n",
       "0               False               False  \n",
       "1               False               False  \n",
       "2               False               False  \n",
       "3               False               False  \n",
       "4               False               False  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "screen_name_cols = ['source_screen_name','destination_screen_name']\n",
    "network_df = pd.DataFrame(pairings, columns = screen_name_cols)\n",
    "network_df['has_mutual_following'] = False #Initialize it to false then compute the follower friend mutual relations\n",
    "network_df['source_follow_dest'] = False\n",
    "network_df['dest_follow_source'] = False  #source is a friend of dest\n",
    "print(network_df.shape)\n",
    "network_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the mutual following info among the list of popular Twitter users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfor index,row in network_df.iterrows():\\n    ff_rel = api.show_friendship(source_screen_name=row['source_screen_name'], target_screen_name=row['destination_screen_name'])\\n    network_df.at[index,'has_mutual_following'] = (ff_rel[0].followed_by == True and ff_rel[0].following == True)\\n    network_df.at[index,'source_follow_dest'] = (ff_rel[0].following == True)\\n    network_df.at[index,'dest_follow_source'] = (ff_rel[0].followed_by == True)\\n\\nprint(network_df.shape)\\nnetwork_df.head()\\nnetwork_df.to_csv('Outputs\\\\mutual_folling_info_retweet_thresh_'+str(retweet_threshold)+'.csv')\\n\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This takes time. Takes about 1 hour for finding connection between every 750 pair of nodes\n",
    "'''\n",
    "for index,row in network_df.iterrows():\n",
    "    ff_rel = api.show_friendship(source_screen_name=row['source_screen_name'], target_screen_name=row['destination_screen_name'])\n",
    "    network_df.at[index,'has_mutual_following'] = (ff_rel[0].followed_by == True and ff_rel[0].following == True)\n",
    "    network_df.at[index,'source_follow_dest'] = (ff_rel[0].following == True)\n",
    "    network_df.at[index,'dest_follow_source'] = (ff_rel[0].followed_by == True)\n",
    "\n",
    "print(network_df.shape)\n",
    "network_df.head()\n",
    "network_df.to_csv('Outputs\\mutual_folling_info_retweet_thresh_'+str(retweet_threshold)+'.csv')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28680, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_screen_name</th>\n",
       "      <th>destination_screen_name</th>\n",
       "      <th>has_mutual_following</th>\n",
       "      <th>source_follow_dest</th>\n",
       "      <th>dest_follow_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>user_54269</td>\n",
       "      <td>user_21251</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>user_54269</td>\n",
       "      <td>user_32545</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>user_54269</td>\n",
       "      <td>user_89002</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>user_54269</td>\n",
       "      <td>user_78819</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>user_54269</td>\n",
       "      <td>user_43012</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  source_screen_name destination_screen_name  has_mutual_following  \\\n",
       "0         user_54269              user_21251                 False   \n",
       "1         user_54269              user_32545                 False   \n",
       "2         user_54269              user_89002                 False   \n",
       "3         user_54269              user_78819                 False   \n",
       "4         user_54269              user_43012                 False   \n",
       "\n",
       "   source_follow_dest  dest_follow_source  \n",
       "0               False               False  \n",
       "1               False               False  \n",
       "2               False               False  \n",
       "3               False               False  \n",
       "4                True               False  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network_df = pd.read_csv('Outputs\\mutual_folling_info_retweet_thresh_'+str(retweet_threshold)+'.csv') #load from saved\n",
    "network_df = network_df.drop(columns='Unnamed: 0',axis=1)\n",
    "network_df['source_screen_name'] = network_df['source_screen_name'].map(mapping_dict)\n",
    "network_df['destination_screen_name'] = network_df['destination_screen_name'].map(mapping_dict)\n",
    "print(network_df.shape)\n",
    "network_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2349"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network_df['has_mutual_following'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of edges (mutual following) in the network is 2349"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7264"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network_df['source_follow_dest'].sum() + network_df['dest_follow_source'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(240, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>screen_name</th>\n",
       "      <th>total_tweet_count</th>\n",
       "      <th>total_retweet_count</th>\n",
       "      <th>max_followers_count</th>\n",
       "      <th>max_friends_count</th>\n",
       "      <th>agg_sentiment_polarity</th>\n",
       "      <th>agg_sentiment_subjectivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>user_10155</td>\n",
       "      <td>9</td>\n",
       "      <td>3511</td>\n",
       "      <td>46494</td>\n",
       "      <td>778</td>\n",
       "      <td>0.154563</td>\n",
       "      <td>0.330952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>user_1024</td>\n",
       "      <td>18</td>\n",
       "      <td>247</td>\n",
       "      <td>3118</td>\n",
       "      <td>1360</td>\n",
       "      <td>0.004818</td>\n",
       "      <td>0.383896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>user_11029</td>\n",
       "      <td>49</td>\n",
       "      <td>50</td>\n",
       "      <td>9782</td>\n",
       "      <td>10720</td>\n",
       "      <td>0.007205</td>\n",
       "      <td>0.252049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>user_1106</td>\n",
       "      <td>13</td>\n",
       "      <td>34</td>\n",
       "      <td>1282</td>\n",
       "      <td>1435</td>\n",
       "      <td>0.055707</td>\n",
       "      <td>0.366349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>user_11431</td>\n",
       "      <td>20</td>\n",
       "      <td>3602</td>\n",
       "      <td>7478</td>\n",
       "      <td>7254</td>\n",
       "      <td>0.081220</td>\n",
       "      <td>0.457911</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  screen_name  total_tweet_count  total_retweet_count  max_followers_count  \\\n",
       "0  user_10155                  9                 3511                46494   \n",
       "1   user_1024                 18                  247                 3118   \n",
       "2  user_11029                 49                   50                 9782   \n",
       "3   user_1106                 13                   34                 1282   \n",
       "4  user_11431                 20                 3602                 7478   \n",
       "\n",
       "   max_friends_count  agg_sentiment_polarity  agg_sentiment_subjectivity  \n",
       "0                778                0.154563                    0.330952  \n",
       "1               1360                0.004818                    0.383896  \n",
       "2              10720                0.007205                    0.252049  \n",
       "3               1435                0.055707                    0.366349  \n",
       "4               7254                0.081220                    0.457911  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network_stats_df_week1 = week1_stats_df[week1_stats_df['screen_name'].isin(all_week_popular_tweeters)].copy()\n",
    "network_stats_df_week1.reset_index(drop=True,inplace=True)\n",
    "\n",
    "network_stats_df_week2 = week2_stats_df[week2_stats_df['screen_name'].isin(all_week_popular_tweeters)].copy()\n",
    "network_stats_df_week2.reset_index(drop=True,inplace=True)\n",
    "\n",
    "network_stats_df_week3 = week3_stats_df[week3_stats_df['screen_name'].isin(all_week_popular_tweeters)].copy()\n",
    "network_stats_df_week3.reset_index(drop=True,inplace=True)\n",
    "\n",
    "network_stats_df_week4 = week4_stats_df[week4_stats_df['screen_name'].isin(all_week_popular_tweeters)].copy()\n",
    "network_stats_df_week4.reset_index(drop=True,inplace=True)\n",
    "\n",
    "network_stats_df_week1.to_csv('Outputs\\week_1_network_retweet_thresh_'+str(retweet_threshold)+'.csv')\n",
    "network_stats_df_week2.to_csv('Outputs\\week_2_network_retweet_thresh_'+str(retweet_threshold)+'.csv')\n",
    "network_stats_df_week3.to_csv('Outputs\\week_3_network_retweet_thresh_'+str(retweet_threshold)+'.csv')\n",
    "network_stats_df_week4.to_csv('Outputs\\week_4_network_retweet_thresh_'+str(retweet_threshold)+'.csv')\n",
    "\n",
    "print(network_stats_df_week1.shape)\n",
    "network_stats_df_week1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network for week 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nplt.figure(figsize=(75,75))\\npos = nx.spring_layout(G, k=1.5*1/np.sqrt(len(G.nodes())), iterations=30)\\n\\nnx.draw(G,pos=pos,with_labels = True,font_size=50,node_size=size_of_nodes,node_color=color_of_nodes,cmap=plt.get_cmap(\\'YlOrBr\\'),seed=10)\\nplt.savefig(\"network_graph_week1_retweet_thresh_\"+str(retweet_threshold)+\".jpeg\") #save as jpeg\\nplt.show() #display\\n'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Plot the mutual relation using networkX library\n",
    "nodes = list(network_stats_df_week1['screen_name'])\n",
    "pd.DataFrame(nodes,columns=['Twitter_users']).to_csv('nodes_list_retweet_thresh_'+str(retweet_threshold)+'.csv')\n",
    "size_of_nodes = list(network_stats_df_week1['total_retweet_count'])\n",
    "color_of_nodes = list(network_stats_df_week1['agg_sentiment_polarity']*2) #Multiply by 2 to see more contrast in colors\n",
    "mutual_follow_lol = network_df[['source_screen_name','destination_screen_name']][network_df['has_mutual_following']==True].values.tolist()\n",
    "pd.DataFrame(mutual_follow_lol,columns=['Twitter_user_1','Twitter_user_2']).to_csv('Outputs\\edges_list_retweet_thresh_'+str(retweet_threshold)+'.csv')\n",
    "mutual_follow_edges = []\n",
    "for mfe in mutual_follow_lol:\n",
    "    mutual_follow_edges.append((mfe[0],mfe[1]))\n",
    "\n",
    "G = nx.Graph()\n",
    "G.add_nodes_from(nodes)\n",
    "G.add_edges_from(mutual_follow_edges)\n",
    "'''\n",
    "plt.figure(figsize=(75,75))\n",
    "pos = nx.spring_layout(G, k=1.5*1/np.sqrt(len(G.nodes())), iterations=30)\n",
    "\n",
    "nx.draw(G,pos=pos,with_labels = True,font_size=50,node_size=size_of_nodes,node_color=color_of_nodes,cmap=plt.get_cmap('YlOrBr'),seed=10)\n",
    "plt.savefig(\"network_graph_week1_retweet_thresh_\"+str(retweet_threshold)+\".jpeg\") #save as jpeg\n",
    "plt.show() #display\n",
    "'''\n",
    "#Intensive color means the sentiment for #Brexit is positive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Popular Social Network Graph of people who have tweeted #Brexit on 1st week of April\n",
    "- Size of nodes indicates number of retweets\n",
    "- Edges indicates mutual following relation\n",
    "- Color of nodes indicates sentiment\n",
    "<img src=\"Images/network_graph_week1_retweet_thresh_10.jpeg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network for week 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nplt.figure(figsize=(75,75))\\npos = nx.spring_layout(G, k=1.5*1/np.sqrt(len(G.nodes())), iterations=20)\\nnx.draw(G,pos=pos,with_labels = True,font_size=50,node_size=size_of_nodes,node_color=color_of_nodes,\\n        cmap=plt.get_cmap(\\'YlOrBr\\'),seed=10)\\nplt.savefig(\"network_graph_week2_retweet_thresh_\"+str(retweet_threshold)+\".jpeg\") #save as jpeg\\nplt.show() #display\\n'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Plot the mutual relation using networkX library\n",
    "nodes = list(network_stats_df_week2['screen_name'])\n",
    "size_of_nodes = list(network_stats_df_week2['total_retweet_count'])\n",
    "color_of_nodes = list(network_stats_df_week2['agg_sentiment_polarity']*2) #Multiply by 2 to see more contrast in colors\n",
    "mutual_follow_lol = network_df[['source_screen_name','destination_screen_name']][network_df['has_mutual_following']==True].values.tolist()\n",
    "mutual_follow_edges = []\n",
    "for mfe in mutual_follow_lol:\n",
    "    mutual_follow_edges.append((mfe[0],mfe[1]))\n",
    "\n",
    "G = nx.Graph()\n",
    "G.add_nodes_from(nodes)\n",
    "G.add_edges_from(mutual_follow_edges)\n",
    "'''\n",
    "plt.figure(figsize=(75,75))\n",
    "pos = nx.spring_layout(G, k=1.5*1/np.sqrt(len(G.nodes())), iterations=20)\n",
    "nx.draw(G,pos=pos,with_labels = True,font_size=50,node_size=size_of_nodes,node_color=color_of_nodes,\n",
    "        cmap=plt.get_cmap('YlOrBr'),seed=10)\n",
    "plt.savefig(\"network_graph_week2_retweet_thresh_\"+str(retweet_threshold)+\".jpeg\") #save as jpeg\n",
    "plt.show() #display\n",
    "'''\n",
    "#Intensive color means the sentiment for #Brexit is positive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Popular Social Network Graph of people who have tweeted #Brexit on 2nd week of April\n",
    "- Size of nodes indicates number of retweets\n",
    "- Edges indicates mutual following relation\n",
    "- Color of nodes indicates sentiment\n",
    "<img src=\"Images/network_graph_week2_retweet_thresh_10.jpeg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network for week 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nnx.draw(G,pos=pos,with_labels = True,font_size=50,node_size=size_of_nodes,node_color=color_of_nodes,\\n        cmap=plt.get_cmap(\\'YlOrBr\\'),seed=10)\\nplt.savefig(\"network_graph_week3_retweet_thresh_\"+str(retweet_threshold)+\".jpeg\") #save as jpeg\\nplt.show() #display\\n'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 5400x5400 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plot the mutual relation using networkX library\n",
    "nodes = list(network_stats_df_week3['screen_name'])\n",
    "size_of_nodes = list(network_stats_df_week3['total_retweet_count'])\n",
    "color_of_nodes = list(network_stats_df_week3['agg_sentiment_polarity']*2) #Multiply by 2 to see more contrast in colors\n",
    "mutual_follow_lol = network_df[['source_screen_name','destination_screen_name']][network_df['has_mutual_following']==True].values.tolist()\n",
    "mutual_follow_edges = []\n",
    "for mfe in mutual_follow_lol:\n",
    "    mutual_follow_edges.append((mfe[0],mfe[1]))\n",
    "\n",
    "G = nx.Graph()\n",
    "G.add_nodes_from(nodes)\n",
    "G.add_edges_from(mutual_follow_edges)\n",
    "plt.figure(figsize=(75,75))\n",
    "pos = nx.spring_layout(G, k=1.5*1/np.sqrt(len(G.nodes())), iterations=25)\n",
    "'''\n",
    "nx.draw(G,pos=pos,with_labels = True,font_size=50,node_size=size_of_nodes,node_color=color_of_nodes,\n",
    "        cmap=plt.get_cmap('YlOrBr'),seed=10)\n",
    "plt.savefig(\"network_graph_week3_retweet_thresh_\"+str(retweet_threshold)+\".jpeg\") #save as jpeg\n",
    "plt.show() #display\n",
    "'''\n",
    "#Intensive color means the sentiment for #Brexit is positive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Popular Social Network Graph of people who have tweeted #Brexit on 3rd week of April\n",
    "- Size of nodes indicates number of retweets\n",
    "- Edges indicates mutual following relation\n",
    "- Color of nodes indicates sentiment\n",
    "<img src=\"Images/network_graph_week3_retweet_thresh_10.jpeg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network for week 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nplt.figure(figsize=(75,75))\\npos = nx.spring_layout(G, k=1.5*1/np.sqrt(len(G.nodes())), iterations=25)\\nnx.draw(G,pos=pos,with_labels = True,font_size=50,node_size=size_of_nodes,node_color=color_of_nodes,\\n        cmap=plt.get_cmap(\\'YlOrBr\\'),seed=10)\\nplt.savefig(\"network_graph_week4_retweet_thresh_\"+str(retweet_threshold)+\".jpeg\") #save as jpeg\\nplt.show() #display\\n'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Plot the mutual relation using networkX library\n",
    "nodes = list(network_stats_df_week4['screen_name'])\n",
    "size_of_nodes = list(network_stats_df_week4['total_retweet_count'])\n",
    "color_of_nodes = list(network_stats_df_week4['agg_sentiment_polarity']*2) #Multiply by 2 to see more contrast in colors\n",
    "mutual_follow_lol = network_df[['source_screen_name','destination_screen_name']][network_df['has_mutual_following']==True].values.tolist()\n",
    "mutual_follow_edges = []\n",
    "for mfe in mutual_follow_lol:\n",
    "    mutual_follow_edges.append((mfe[0],mfe[1]))\n",
    "\n",
    "G = nx.Graph()\n",
    "G.add_nodes_from(nodes)\n",
    "G.add_edges_from(mutual_follow_edges)\n",
    "'''\n",
    "plt.figure(figsize=(75,75))\n",
    "pos = nx.spring_layout(G, k=1.5*1/np.sqrt(len(G.nodes())), iterations=25)\n",
    "nx.draw(G,pos=pos,with_labels = True,font_size=50,node_size=size_of_nodes,node_color=color_of_nodes,\n",
    "        cmap=plt.get_cmap('YlOrBr'),seed=10)\n",
    "plt.savefig(\"network_graph_week4_retweet_thresh_\"+str(retweet_threshold)+\".jpeg\") #save as jpeg\n",
    "plt.show() #display\n",
    "'''\n",
    "#Intensive color means the sentiment for #Brexit is positive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Popular Social Network Graph of people who have tweeted #Brexit on 4th week of April\n",
    "- Size of nodes indicates number of retweets\n",
    "- Edges indicates mutual following relation\n",
    "- Color of nodes indicates sentiment\n",
    "<img src=\"Images/network_graph_week4_retweet_thresh_10.jpeg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph Algorithms (Undirected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connectivity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ALL NODE CONNECTIVITY\n",
    "Compute node connectivity between all pairs of nodes. (This call takes time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#network_all_node_pair_connectivity = approx.all_pairs_node_connectivity(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### LOCAL NODE CONNECTIVITY\n",
    "Give a source node & a target node to check if there is a connectivity between them. <br>\n",
    "Local node connectivity for two non adjacent nodes s and t is the minimum number of nodes that must be removed (along with their incident edges) to disconnect them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from networkx.algorithms import approximation as approx\n",
    "network_local_node_connectivity = approx.local_node_connectivity(G,'user_35532','user_17872')\n",
    "network_local_node_connectivity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### NODE CONNECTIVITY\n",
    "Returns node connectivity for a graph or digraph G. <br>\n",
    "Node connectivity is equal to the minimum number of nodes that must be removed to disconnect G or render it trivial. If source and target nodes are provided, this function returns the local node connectivity: the minimum number of nodes that must be removed to break all paths from source to target in G."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network_node_connectivity = approx.node_connectivity(G)\n",
    "network_node_connectivity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### BIPARTITE CLUSTERING\n",
    "Compute a bipartite clustering coefficient for nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nx.algorithms.bipartite.clustering(G) #The graph is not bipartite, so it produces error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### CLUSTER TRIANGLES\n",
    "Finds the number of triangles that include a node as one vertex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('user_92741', 1391),\n",
       " ('user_84416', 1283),\n",
       " ('user_44225', 1258),\n",
       " ('user_3678', 1186),\n",
       " ('user_42890', 1161),\n",
       " ('user_57298', 1160),\n",
       " ('user_20654', 1152),\n",
       " ('user_17859', 1138),\n",
       " ('user_15822', 1136),\n",
       " ('user_48474', 1098)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network_clustering_triangles = nx.triangles(G)\n",
    "sorted(network_clustering_triangles.items(), key=lambda x: x[1],reverse=True)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### CLUSTER TRANSITIVITY\n",
    "Compute graph transitivity, the fraction of all possible triangles present in G.<br>\n",
    "Possible triangles are identified by the number of “triads” (two edges with a shared vertex)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5360104570681637"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network_clustering_transitivity = nx.transitivity(G)\n",
    "network_clustering_transitivity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### SQUARE CLUSTERING\n",
    "Compute the squares clustering coefficient for nodes. <br>\n",
    "For each node return the fraction of possible squares that exist at the node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('user_94349', 0.28558008454673556),\n",
       " ('user_74305', 0.1870406943156933),\n",
       " ('user_80677', 0.15698987890836796),\n",
       " ('user_47010', 0.15256036873675907),\n",
       " ('user_87390', 0.15028773793714031),\n",
       " ('user_67536', 0.14956017514102007),\n",
       " ('user_62278', 0.14862690556055524),\n",
       " ('user_48786', 0.14755314522524365),\n",
       " ('user_58611', 0.1469646154425896),\n",
       " ('user_66427', 0.1452530772894783)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network_square_clustering = nx.square_clustering(G)\n",
    "sorted(network_square_clustering.items(), key=lambda x: x[1],reverse=True)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### CLUSTERING\n",
    "Compute the clustering coefficient for nodes. <br>\n",
    "For unweighted graphs, the clustering of a node u is the fraction of possible triangles through that node that exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('user_43189', 1.0),\n",
       " ('user_65597', 1.0),\n",
       " ('user_94349', 0.9722222222222222),\n",
       " ('user_7443', 0.9047619047619048),\n",
       " ('user_54257', 0.8333333333333334),\n",
       " ('user_58611', 0.8333333333333334),\n",
       " ('user_87390', 0.8225806451612904),\n",
       " ('user_74305', 0.8068783068783069),\n",
       " ('user_38508', 0.8),\n",
       " ('user_5725', 0.8)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network_clustering = nx.clustering(G)\n",
    "sorted(network_clustering.items(), key=lambda x: x[1],reverse=True)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### AVERAGE CLUSTERING\n",
    "Estimates the average clustering coefficient of G."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.41115590293803694"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network_average_clustering = nx.average_clustering(G)\n",
    "network_average_clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### GENERALIZED DEGREE\n",
    "Compute the generalized degree for nodes. <br>\n",
    "For each node, the generalized degree shows how many edges of given triangle multiplicity the node is connected to. The triangle multiplicity of an edge is the number of triangles an edge participates in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 1})\n",
      "Counter({4: 4, 5: 2, 8: 1, 3: 1, 6: 1, 2: 1, 7: 1})\n"
     ]
    }
   ],
   "source": [
    "network_generalized_degree = nx.generalized_degree(G)\n",
    "print(network_generalized_degree['user_35532'])\n",
    "print(network_generalized_degree['user_61373'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Centrality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### DEGREE CENTRALITY\n",
    "Compute the degree centrality for nodes. <br>\n",
    "The degree centrality for a node v is the fraction of nodes it is connected to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('user_92741', 0.34728033472803344),\n",
       " ('user_44225', 0.3305439330543933),\n",
       " ('user_84416', 0.3263598326359832),\n",
       " ('user_3678', 0.305439330543933),\n",
       " ('user_20654', 0.29707112970711297),\n",
       " ('user_61379', 0.2928870292887029),\n",
       " ('user_42890', 0.2845188284518828),\n",
       " ('user_15822', 0.28033472803347276),\n",
       " ('user_17859', 0.2719665271966527),\n",
       " ('user_57298', 0.2719665271966527)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network_degree_centrality = nx.degree_centrality(G)\n",
    "sorted(network_degree_centrality.items(), key=lambda x: x[1],reverse=True)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### EIGENVECTOR CENTRALITY\n",
    "Compute the eigenvector centrality for the graph G. <br>\n",
    "Eigenvector centrality computes the centrality for a node based on the centrality of its neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('user_92741', 0.17348576620042236),\n",
       " ('user_84416', 0.166450250620681),\n",
       " ('user_44225', 0.16406086008344295),\n",
       " ('user_3678', 0.16029369536136398),\n",
       " ('user_57298', 0.15739072469917165),\n",
       " ('user_20654', 0.15705114078841137),\n",
       " ('user_42890', 0.15685190782988093),\n",
       " ('user_17859', 0.1559405548902361),\n",
       " ('user_15822', 0.15565096385877436),\n",
       " ('user_48474', 0.15339907605386296)]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network_eigenvector_centrality = nx.eigenvector_centrality(G)\n",
    "sorted(network_eigenvector_centrality.items(), key=lambda x: x[1],reverse=True)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### CLOSENESS CENTRALITY\n",
    "Compute closeness centrality for nodes. <br>\n",
    "Closeness centrality of a node u is the reciprocal of the average shortest path distance to u over all n-1 reachable nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('user_44225', 0.5070859765150493),\n",
       " ('user_61379', 0.5008716875871687),\n",
       " ('user_52937', 0.47970809515390817),\n",
       " ('user_20654', 0.4763534930898948),\n",
       " ('user_3678', 0.4697831000817583),\n",
       " ('user_92741', 0.4697831000817583),\n",
       " ('user_42890', 0.46656540761544496),\n",
       " ('user_15822', 0.46444465576264743),\n",
       " ('user_95542', 0.46444465576264743),\n",
       " ('user_13335', 0.46339149327792484)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network_closeness_centrality = nx.closeness_centrality(G)\n",
    "sorted(network_closeness_centrality.items(), key=lambda x: x[1],reverse=True)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### BETWEENNESS CENTRALITY\n",
    "Compute the shortest-path betweenness centrality for nodes. <br>\n",
    "Betweenness centrality of a node v is the sum of the fraction of all-pairs shortest paths that pass through v."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('user_61379', 0.10730944737937745),\n",
       " ('user_44225', 0.08452071997138032),\n",
       " ('user_43280', 0.05153190002908908),\n",
       " ('user_52937', 0.04812279584162896),\n",
       " ('user_41762', 0.03997594854822955),\n",
       " ('user_89002', 0.03989287766002407),\n",
       " ('user_44816', 0.0385338188447167),\n",
       " ('user_68318', 0.03211931475974364),\n",
       " ('user_36827', 0.03201759162831476),\n",
       " ('user_84416', 0.031925313476213676)]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network_betweenness_centrality = nx.betweenness_centrality(G)\n",
    "sorted(network_betweenness_centrality.items(), key=lambda x: x[1],reverse=True)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### EDGE BETWEENNESS CENTRALITY\n",
    "Compute betweenness centrality for edges. <br>\n",
    "Betweenness centrality of an edge e is the sum of the fraction of all-pairs shortest paths that pass through e."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('user_13730', 'user_68318'), 0.03205716734157897),\n",
       " (('user_12973', 'user_13730'), 0.030404463040446306),\n",
       " (('user_44225', 'user_68318'), 0.02813210119291191),\n",
       " (('user_12973', 'user_17872'), 0.015341701534170154),\n",
       " (('user_12507', 'user_16803'), 0.013132408566267479),\n",
       " (('user_34599', 'user_60456'), 0.012463734563953666),\n",
       " (('user_44225', 'user_89002'), 0.011991079682978226),\n",
       " (('user_17596', 'user_44225'), 0.011544631530768816),\n",
       " (('user_36827', 'user_61379'), 0.01064916168404423),\n",
       " (('user_44816', 'user_87299'), 0.010565839052837308)]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network_edge_betweenness_centrality = nx.edge_betweenness_centrality(G)\n",
    "sorted(network_edge_betweenness_centrality.items(), key=lambda x: x[1],reverse=True)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Centrality Plot\n",
    "The idea behind this plot is to know where the nodes with some of the highest centrality measures are located in the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nplt.figure(figsize=(75,75))\\npos = nx.spring_layout(G, k=3*1/np.sqrt(len(G.nodes())), iterations=25)\\nnx.draw(G,pos=pos,with_labels = True,font_size=50,node_size=size_of_nodes,node_color=color_of_nodes,\\n        cmap=plt.get_cmap(\\'YlOrBr\\'),seed=10)\\nplt.savefig(\"centrality.jpeg\") #save as jpeg\\nplt.show() #display\\n'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_centrality = network_stats_df_week1.copy()\n",
    "df_centrality.head()\n",
    "df_centrality['color'] = 'gold'\n",
    "df_centrality['total_retweet_count'] = 500\n",
    "df_centrality.at[224,'total_retweet_count'] = 10000  #(user_92741)\n",
    "df_centrality.at[149,'total_retweet_count'] = 10000  #(user_61379)\n",
    "df_centrality.at[102,'total_retweet_count'] = 10000  #(user_44225)\n",
    "\n",
    "df_centrality.at[224,'color'] = 'red'  #Degree Centrality & Eigenvector centrality (user_92741)\n",
    "df_centrality.at[149,'color'] = 'lime'  #Betweenness Centrality (user_61379)\n",
    "df_centrality.at[102,'color'] = 'magenta'  #Closeness Centrality (user_44225)\n",
    "\n",
    "color_of_nodes = list(df_centrality['color']) #Multiply by 2 to see more contrast in colors\n",
    "nodes = list(df_centrality['screen_name'])\n",
    "size_of_nodes = list(df_centrality['total_retweet_count'])\n",
    "mutual_follow_lol = network_df[['source_screen_name','destination_screen_name']][network_df['has_mutual_following']==True].values.tolist()\n",
    "mutual_follow_edges = []\n",
    "for mfe in mutual_follow_lol:\n",
    "    mutual_follow_edges.append((mfe[0],mfe[1]))\n",
    "\n",
    "G = nx.Graph()\n",
    "G.add_nodes_from(nodes)\n",
    "G.add_edges_from(mutual_follow_edges)\n",
    "'''\n",
    "plt.figure(figsize=(75,75))\n",
    "pos = nx.spring_layout(G, k=3*1/np.sqrt(len(G.nodes())), iterations=25)\n",
    "nx.draw(G,pos=pos,with_labels = True,font_size=50,node_size=size_of_nodes,node_color=color_of_nodes,\n",
    "        cmap=plt.get_cmap('YlOrBr'),seed=10)\n",
    "plt.savefig(\"centrality.jpeg\") #save as jpeg\n",
    "plt.show() #display\n",
    "'''\n",
    "#Intensive color means the sentiment for #Brexit is positive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Centrality Plot\n",
    "<img src=\"Images/centrality.jpeg\">\n",
    "In the above graph: <br>\n",
    "- The red coloured node represents twitter user of high degree centrality & high eigenvector centrality. \n",
    "- The green coloured node represents twitter user of high betweenness centrality. \n",
    "- The magenta coloured node represents twitter user of high closeness centrality.  <br>\n",
    "\n",
    "Analysis of centrality measures can be helpful in <i>finding who are the main influencers in the network, finding the source of fake news, fraud detection</i> etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Communicability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Return communicability between all pairs of nodes in G. <br>\n",
    "The communicability between pairs of nodes in G is the sum of closed walks of different lengths starting at node u and ending at node v."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('user_92741', 1.9266768407210386e+18),\n",
       " ('user_84416', 1.8485433726343764e+18),\n",
       " ('user_44225', 1.8219986486205778e+18),\n",
       " ('user_3678', 1.7801676649838587e+18),\n",
       " ('user_57298', 1.7479288234139569e+18),\n",
       " ('user_20654', 1.7441566860271252e+18),\n",
       " ('user_42890', 1.7419457973843866e+18),\n",
       " ('user_17859', 1.7318258482502144e+18),\n",
       " ('user_15822', 1.728608771612648e+18),\n",
       " ('user_48474', 1.7035979898308593e+18)]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network_communicatability = nx.communicability(G)\n",
    "#network_communicatability['user_0'] #Shows the communicability of user_0 with all other nodes\n",
    "sorted(network_communicatability['user_44225'].items(), key=lambda x: x[1],reverse=True)[:10] #Top 10 nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### COMMUNICABILITY BETWEENNESS CENTRALITY\n",
    "- communicability() - Communicability between pairs of nodes in G.\n",
    "- communicability_betweenness_centrality() - Communicability betweeness centrality for each node in G."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Triguna\\AppData\\Roaming\\Python\\Python37\\site-packages\\networkx\\algorithms\\centrality\\subgraph_alg.py:246: RuntimeWarning: invalid value encountered in true_divide\n",
      "  B = (expA - scipy.linalg.expm(A.A)) / expA\n"
     ]
    }
   ],
   "source": [
    "network_communicatability_bw_centrality = nx.communicability_betweenness_centrality(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Link Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### PAGERANK\n",
    "PageRank analysis of graph structure. <br>\n",
    "PageRank computes a ranking of the nodes in the graph G based on the structure of the incoming links. It was originally designed as an algorithm to rank web pages. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('user_61379', 0.014508408683615682),\n",
       " ('user_44225', 0.013261792034877443),\n",
       " ('user_92741', 0.013083332893889622),\n",
       " ('user_84416', 0.012904765954242633),\n",
       " ('user_43280', 0.01186284582726005),\n",
       " ('user_20654', 0.011628817381389286),\n",
       " ('user_3678', 0.01143823851463272),\n",
       " ('user_42890', 0.01114367442676755),\n",
       " ('user_15822', 0.010453559304481873),\n",
       " ('user_89002', 0.010304839764382142)]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network_pagerank = nx.pagerank(G)\n",
    "sorted(network_pagerank.items(), key=lambda x: x[1],reverse=True)[:10] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### HITS\n",
    "Return HITS hubs and authorities values for nodes. <br>\n",
    "The HITS algorithm computes two numbers for a node. Authorities estimates the node value based on the incoming links. Hubs estimates the node value based on outgoing links."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_hubs,network_authorities = nx.hits(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### MINIMUM SPANNING TREE\n",
    "Returns a minimum spanning tree or forest on an undirected graph G."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('user_10155', 'user_50014', {}),\n",
       " ('user_10155', 'user_6055', {}),\n",
       " ('user_10155', 'user_86539', {}),\n",
       " ('user_1024', 'user_43237', {}),\n",
       " ('user_1024', 'user_53291', {}),\n",
       " ('user_1024', 'user_58600', {}),\n",
       " ('user_1024', 'user_60456', {}),\n",
       " ('user_1024', 'user_61379', {}),\n",
       " ('user_1024', 'user_67550', {}),\n",
       " ('user_1024', 'user_7058', {})]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network_min_spanning_tree = nx.minimum_spanning_tree(G)\n",
    "sorted(network_min_spanning_tree.edges(data=True))[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### MAXIMUM SPANNING TREE\n",
    "Returns a maximum spanning tree or forest on an undirected graph G."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('user_10155', 'user_50014', {}),\n",
       " ('user_10155', 'user_6055', {}),\n",
       " ('user_10155', 'user_86539', {}),\n",
       " ('user_1024', 'user_43237', {}),\n",
       " ('user_1024', 'user_53291', {}),\n",
       " ('user_1024', 'user_58600', {}),\n",
       " ('user_1024', 'user_60456', {}),\n",
       " ('user_1024', 'user_61379', {}),\n",
       " ('user_1024', 'user_67550', {}),\n",
       " ('user_1024', 'user_7058', {})]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network_max_spanning_tree = nx.maximum_spanning_tree(G)\n",
    "sorted(network_max_spanning_tree.edges(data=True))[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### MINIMUM SPANNING EDGES\n",
    "Generate edges in a minimum spanning forest of an undirected weighted graph. <br>\n",
    "A minimum spanning tree is a subgraph of the graph (a tree) with the minimum sum of edge weights. A spanning forest is a union of the spanning trees for each connected component of the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('user_10155', 'user_50014', {}),\n",
       " ('user_10155', 'user_6055', {}),\n",
       " ('user_10155', 'user_86539', {}),\n",
       " ('user_1024', 'user_43237', {}),\n",
       " ('user_1024', 'user_53291', {}),\n",
       " ('user_1024', 'user_58600', {}),\n",
       " ('user_1024', 'user_60456', {}),\n",
       " ('user_1024', 'user_61379', {}),\n",
       " ('user_1024', 'user_67550', {}),\n",
       " ('user_1024', 'user_7058', {})]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network_min_spanning_edges = nx.minimum_spanning_edges(G)\n",
    "sorted(list(network_min_spanning_edges))[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### MAXIMUM SPANNING EDGES\n",
    "Generate edges in a maximum spanning forest of an undirected weighted graph. <br>\n",
    "A maximum spanning tree is a subgraph of the graph (a tree) with the maximum possible sum of edge weights. A spanning forest is a union of the spanning trees for each connected component of the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('user_10155', 'user_50014', {}),\n",
       " ('user_10155', 'user_6055', {}),\n",
       " ('user_10155', 'user_86539', {}),\n",
       " ('user_1024', 'user_43237', {}),\n",
       " ('user_1024', 'user_53291', {}),\n",
       " ('user_1024', 'user_58600', {}),\n",
       " ('user_1024', 'user_60456', {}),\n",
       " ('user_1024', 'user_61379', {}),\n",
       " ('user_1024', 'user_67550', {}),\n",
       " ('user_1024', 'user_7058', {})]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network_max_spanning_edges = nx.maximum_spanning_edges(G)\n",
    "sorted(list(network_max_spanning_edges))[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vitality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### CLOSENESS VITALITY\n",
    "Returns the closeness vitality for nodes in the graph. <br>\n",
    "The closeness vitality of a node is the change in the sum of distances between all node pairs when excluding that node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_vitality = nx.closeness_vitality(G)#Requires closely connected graph, else returns nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wiener index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Returns the Wiener index of the given graph. <br>\n",
    "The Wiener index of a graph is the sum of the shortest-path distances between each pair of reachable nodes. For pairs of nodes in undirected graphs, only one orientation of the pair is counted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "inf"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nx.wiener_index(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Community Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KERNIGHAN–LIN (BIPARTITIAN) COMMUNITY\n",
    "Partition a graph into two blocks using the Kernighan–Lin algorithm. <br>\n",
    "This algorithm paritions a network into two sets by iteratively swapping pairs of nodes to reduce the edge cut between the two sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network_community_kl = nx.community.kernighan_lin.kernighan_lin_bisection(G) \n",
    "#It may give better results if we give the weights of edges\n",
    "len(network_community_kl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GREEDY MODULARITY COMMUNITY\n",
    "Find communities in graph using Clauset-Newman-Moore greedy modularity maximization. <br>\n",
    "This method currently supports the Graph class and does not consider edge weights. Greedy modularity maximization begins with each node in its own community and joins the pair of communities that most increases modularity until no such pair exists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network_community_modularity = nx.community.greedy_modularity_communities(G)\n",
    "len(network_community_modularity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K-CLIQUE COMMUNITY DETECTION\n",
    "Find k-clique communities in graph using the percolation method. <br>\n",
    "A k-clique community is the union of all cliques of size k that can be reached through adjacent (sharing k-1 nodes) k-cliques. <br>\n",
    "This community detection algorithm is mainly used to detect overlapping communities in a network. k-clique is a clique with k nodes. K-clique community is a union of all k-cliques that can be reached from each other through a series of adjacent k-cliques. Two k-cliques are said to be adjacent if they share k-1 nodes. We usually consider maximal cliques for this algorithm. In this network, optimal results was found for k=5. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network_community_k_clique = nx.community.k_clique_communities(G,5) #Set k = 5\n",
    "network_community_k_clique = list(network_community_k_clique)\n",
    "len(network_community_k_clique)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LABEL PROPAGATION COMMUNITY\n",
    "Generates community sets determined by label propagation. <br>\n",
    "The algorithm works by propagating labels throughout the network and forming communities based on this process of label propagation. The idea is, within a cluster, all nodes connected to each other, will eventually converge to the same label. The intuition behind the algorithm is that a single label can quickly become dominant in a densely connected group of nodes but will have trouble crossing a sparsely connected region. The algorithm stops when every node has a label that the maximum no. of their neighbour has."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network_community_lpa = nx.community.label_propagation.label_propagation_communities(G)\n",
    "network_community_lpa = list(network_community_lpa)[::-1]\n",
    "len(network_community_lpa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GIRVAN–NEWMAN COMMUNITY\n",
    "Finds communities in a graph using the Girvan–Newman method. <br>\n",
    "The Girvan–Newman algorithm detects communities by progressively removing edges from the original graph. The algorithm removes the “most valuable” edge, traditionally the edge with the highest betweenness centrality, at each step. As the graph breaks down into pieces, the tightly knit community structure is exposed and the result can be depicted as a dendrogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network_community_gn = nx.community.centrality.girvan_newman(G)\n",
    "network_community_gn = list(tuple(set(c) for c in next(network_community_gn)))\n",
    "len(network_community_gn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LOUVAIN METHOD\n",
    "A very popular heuristic algorithm used for community detection. It maximizes modularity score for each community. The algorithm first assigns each node to its own community and then goes through each node and evaluate the modularity gain from removing the node from its own community and placing to its neighbouring community. The procedure is repeated until the modularity score keeps increasing. When clusters cannot be improved further by moving individual nodes, the Louvain algorithm aggregates the network, so that each cluster in the original network becomes a node in the aggregated network. In the aggregated network, the algorithm then starts to move individual nodes from one cluster to another. By repeating the node movement and aggregation, the Louvain algorithm is able to find high-quality clusters in a short time. Since the Louvain algorithm keeps moving nodes from one cluster to another, at some point it may move the crucial node to a different cluster, thereby breaking the connectivity of the original cluster. Perhaps surprisingly, the Louvain algorithm cannot fix this shattered connectivity.  Also, this method reaches to a local maximum modularity based on the order of nodes chosen. And hence results in different final distributions of communities each time. The issue with this algorithm is they have trouble detecting small communities in large networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!pip install python-louvain\n",
    "import community\n",
    "partition = community.best_partition(G)\n",
    "network_community_louvain = []\n",
    "for i in range(len(set(partition.values()))):\n",
    "    community_members = []\n",
    "    for key, value in partition.items():\n",
    "        if value == i:\n",
    "            community_members.append(key)\n",
    "    network_community_louvain.append(set(community_members))\n",
    "    \n",
    "len(network_community_louvain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LEIDEN METHOD\n",
    "The problem of shattered connectivity in Louvain algorithm is fixed in the Leiden algorithm. The Leiden algorithm is able to split clusters instead of only merging them, as is done by the Louvain algorithm. By splitting clusters in a specific way, the Leiden algorithm guarantees that clusters are well-connected. It is impossible to improve the quality of the clusters by moving one or more nodes from one cluster to another. This is a strong property of the Leiden algorithm. It states that the clusters it finds are not too far from optimal. Finally, rather than continuously checking for all nodes in a network whether they can be moved to a different cluster, as is done in the Louvain algorithm, the Leiden algorithm performs this check only for so-called unstable nodes. As a result, the Leiden algorithm does not only find higher quality clusters than the Louvain algorithm, it also does so in much less time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#I wasn't able to install this in my local laptop, but I was able to run it on Google Colab and save the results on dataframe\n",
    "#!pip install leidenalg  \n",
    "#import leidenalg\n",
    "#!pip install igraph\n",
    "#import igraph as ig\n",
    "#nx.write_graphml(G,'graph.graphml')\n",
    "#Gix = ig.read('graph.graphml',format=\"graphml\")\n",
    "#network_community_leiden = leidenalg.find_partition(Gix, leidenalg.ModularityVertexPartition);\n",
    "#network_community_leiden = list(network_community_leiden)\n",
    "leiden_df = pd.read_csv('leiden_df.csv')[['screen_name','leiden_ID']] #Saved dataframe after running it on Google Colab\n",
    "leiden_df['screen_name'] = leiden_df['screen_name'].map(mapping_dict)\n",
    "\n",
    "group_ids = list(set(leiden_df['leiden_ID']))\n",
    "network_community_leiden = []\n",
    "for ids in group_ids:\n",
    "    network_community_leiden.append((set(leiden_df['screen_name'][leiden_df['leiden_ID']==ids])))\n",
    "    \n",
    "len(network_community_leiden)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the communities detected by various community detection algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(240, 21)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>screen_name</th>\n",
       "      <th>total_tweet_count</th>\n",
       "      <th>total_retweet_count</th>\n",
       "      <th>max_followers_count</th>\n",
       "      <th>max_friends_count</th>\n",
       "      <th>agg_sentiment_polarity</th>\n",
       "      <th>agg_sentiment_subjectivity</th>\n",
       "      <th>kernighanLin_ID</th>\n",
       "      <th>kernighanLin_size</th>\n",
       "      <th>GModularity_ID</th>\n",
       "      <th>...</th>\n",
       "      <th>kClique_ID</th>\n",
       "      <th>kClique_size</th>\n",
       "      <th>labelProp_ID</th>\n",
       "      <th>labelProp_size</th>\n",
       "      <th>girvanNew_ID</th>\n",
       "      <th>girvanNew_size</th>\n",
       "      <th>louvain_ID</th>\n",
       "      <th>louvain_size</th>\n",
       "      <th>leiden_ID</th>\n",
       "      <th>leiden_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>user_10155</td>\n",
       "      <td>9</td>\n",
       "      <td>3511</td>\n",
       "      <td>46494</td>\n",
       "      <td>778</td>\n",
       "      <td>0.154563</td>\n",
       "      <td>0.330952</td>\n",
       "      <td>0</td>\n",
       "      <td>2500</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>500</td>\n",
       "      <td>4</td>\n",
       "      <td>2500</td>\n",
       "      <td>0</td>\n",
       "      <td>2500</td>\n",
       "      <td>0</td>\n",
       "      <td>2500</td>\n",
       "      <td>2</td>\n",
       "      <td>2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>user_1024</td>\n",
       "      <td>18</td>\n",
       "      <td>247</td>\n",
       "      <td>3118</td>\n",
       "      <td>1360</td>\n",
       "      <td>0.004818</td>\n",
       "      <td>0.383896</td>\n",
       "      <td>0</td>\n",
       "      <td>2500</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2500</td>\n",
       "      <td>5</td>\n",
       "      <td>2500</td>\n",
       "      <td>0</td>\n",
       "      <td>2500</td>\n",
       "      <td>1</td>\n",
       "      <td>2500</td>\n",
       "      <td>0</td>\n",
       "      <td>2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>user_11029</td>\n",
       "      <td>49</td>\n",
       "      <td>50</td>\n",
       "      <td>9782</td>\n",
       "      <td>10720</td>\n",
       "      <td>0.007205</td>\n",
       "      <td>0.252049</td>\n",
       "      <td>1</td>\n",
       "      <td>2500</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2500</td>\n",
       "      <td>4</td>\n",
       "      <td>2500</td>\n",
       "      <td>0</td>\n",
       "      <td>2500</td>\n",
       "      <td>2</td>\n",
       "      <td>2500</td>\n",
       "      <td>1</td>\n",
       "      <td>2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>user_1106</td>\n",
       "      <td>13</td>\n",
       "      <td>34</td>\n",
       "      <td>1282</td>\n",
       "      <td>1435</td>\n",
       "      <td>0.055707</td>\n",
       "      <td>0.366349</td>\n",
       "      <td>0</td>\n",
       "      <td>2500</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2500</td>\n",
       "      <td>5</td>\n",
       "      <td>2500</td>\n",
       "      <td>0</td>\n",
       "      <td>2500</td>\n",
       "      <td>1</td>\n",
       "      <td>2500</td>\n",
       "      <td>0</td>\n",
       "      <td>2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>user_11431</td>\n",
       "      <td>20</td>\n",
       "      <td>3602</td>\n",
       "      <td>7478</td>\n",
       "      <td>7254</td>\n",
       "      <td>0.081220</td>\n",
       "      <td>0.457911</td>\n",
       "      <td>1</td>\n",
       "      <td>2500</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2500</td>\n",
       "      <td>4</td>\n",
       "      <td>2500</td>\n",
       "      <td>0</td>\n",
       "      <td>2500</td>\n",
       "      <td>2</td>\n",
       "      <td>2500</td>\n",
       "      <td>1</td>\n",
       "      <td>2500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  screen_name  total_tweet_count  total_retweet_count  max_followers_count  \\\n",
       "0  user_10155                  9                 3511                46494   \n",
       "1   user_1024                 18                  247                 3118   \n",
       "2  user_11029                 49                   50                 9782   \n",
       "3   user_1106                 13                   34                 1282   \n",
       "4  user_11431                 20                 3602                 7478   \n",
       "\n",
       "   max_friends_count  agg_sentiment_polarity  agg_sentiment_subjectivity  \\\n",
       "0                778                0.154563                    0.330952   \n",
       "1               1360                0.004818                    0.383896   \n",
       "2              10720                0.007205                    0.252049   \n",
       "3               1435                0.055707                    0.366349   \n",
       "4               7254                0.081220                    0.457911   \n",
       "\n",
       "  kernighanLin_ID  kernighanLin_size GModularity_ID     ...      kClique_ID  \\\n",
       "0               0               2500              0     ...                   \n",
       "1               0               2500              1     ...               1   \n",
       "2               1               2500              0     ...               0   \n",
       "3               0               2500              1     ...               1   \n",
       "4               1               2500              0     ...               0   \n",
       "\n",
       "  kClique_size  labelProp_ID labelProp_size  girvanNew_ID girvanNew_size  \\\n",
       "0          500             4           2500             0           2500   \n",
       "1         2500             5           2500             0           2500   \n",
       "2         2500             4           2500             0           2500   \n",
       "3         2500             5           2500             0           2500   \n",
       "4         2500             4           2500             0           2500   \n",
       "\n",
       "   louvain_ID louvain_size  leiden_ID leiden_size  \n",
       "0           0         2500          2        2500  \n",
       "1           1         2500          0        2500  \n",
       "2           2         2500          1        2500  \n",
       "3           1         2500          0        2500  \n",
       "4           2         2500          1        2500  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "community_df = network_stats_df_week1.copy()\n",
    "community_df['kernighanLin_ID'] = '' #Bipartitian\n",
    "community_df['kernighanLin_size'] = 500\n",
    "community_df['GModularity_ID'] = ''\n",
    "community_df['GModularity_size'] = 500\n",
    "community_df['kClique_ID'] = ''\n",
    "community_df['kClique_size'] = 500\n",
    "community_df['labelProp_ID'] = ''\n",
    "community_df['labelProp_size'] = 500\n",
    "community_df['girvanNew_ID'] = ''\n",
    "community_df['girvanNew_size'] = 500\n",
    "community_df['louvain_ID'] = ''\n",
    "community_df['louvain_size'] = 500\n",
    "community_df['leiden_ID'] = ''\n",
    "community_df['leiden_size'] = 500\n",
    "for index,row in community_df.iterrows():\n",
    "    for h in range(len(network_community_kl)):\n",
    "        if row['screen_name'] in network_community_kl[h]:\n",
    "            community_df.at[index,'kernighanLin_ID'] = h\n",
    "            community_df.at[index,'kernighanLin_size'] = 2500\n",
    "    for i in range(len(network_community_modularity)):\n",
    "        if len(network_community_modularity[i]) >= 3:  #Only consider communities having at least 3 members\n",
    "            if row['screen_name'] in network_community_modularity[i]:\n",
    "                community_df.at[index,'GModularity_ID'] = i\n",
    "                community_df.at[index,'GModularity_size'] = 2500\n",
    "    for j in range(len(network_community_k_clique)):\n",
    "        if row['screen_name'] in network_community_k_clique[j]:\n",
    "            community_df.at[index,'kClique_ID'] = j\n",
    "            community_df.at[index,'kClique_size'] = 2500\n",
    "    for k in range(len(network_community_lpa)):\n",
    "        if len(network_community_lpa[k]) >= 3:  #Only consider communities having at least 3 members\n",
    "            if row['screen_name'] in network_community_lpa[k]:\n",
    "                community_df.at[index,'labelProp_ID'] = k\n",
    "                community_df.at[index,'labelProp_size'] = 2500\n",
    "    for l in range(len(network_community_gn)):\n",
    "        if len(network_community_gn[l]) >= 3:  #Only consider communities having at least 3 members\n",
    "            if row['screen_name'] in network_community_gn[l]:\n",
    "                community_df.at[index,'girvanNew_ID'] = l\n",
    "                community_df.at[index,'girvanNew_size'] = 2500\n",
    "    for m in range(len(network_community_louvain)):\n",
    "        if len(network_community_louvain[m]) >= 3:  #Only consider communities having at least 3 members\n",
    "            if row['screen_name'] in network_community_louvain[m]:\n",
    "                community_df.at[index,'louvain_ID'] = m\n",
    "                community_df.at[index,'louvain_size'] = 2500\n",
    "    for n in range(len(network_community_leiden)):\n",
    "        if len(network_community_leiden[n]) >= 3:  #Only consider communities having at least 3 members\n",
    "            if row['screen_name'] in network_community_leiden[n]:\n",
    "                community_df.at[index,'leiden_ID'] = n\n",
    "                community_df.at[index,'leiden_size'] = 2500\n",
    "print(community_df.shape)\n",
    "community_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>screen_name</th>\n",
       "      <th>total_tweet_count</th>\n",
       "      <th>total_retweet_count</th>\n",
       "      <th>max_followers_count</th>\n",
       "      <th>max_friends_count</th>\n",
       "      <th>agg_sentiment_polarity</th>\n",
       "      <th>agg_sentiment_subjectivity</th>\n",
       "      <th>kernighanLin_ID</th>\n",
       "      <th>kernighanLin_size</th>\n",
       "      <th>GModularity_ID</th>\n",
       "      <th>...</th>\n",
       "      <th>kClique_ID</th>\n",
       "      <th>kClique_size</th>\n",
       "      <th>labelProp_ID</th>\n",
       "      <th>labelProp_size</th>\n",
       "      <th>girvanNew_ID</th>\n",
       "      <th>girvanNew_size</th>\n",
       "      <th>louvain_ID</th>\n",
       "      <th>louvain_size</th>\n",
       "      <th>leiden_ID</th>\n",
       "      <th>leiden_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>user_10155</td>\n",
       "      <td>9</td>\n",
       "      <td>3511</td>\n",
       "      <td>46494</td>\n",
       "      <td>778</td>\n",
       "      <td>0.154563</td>\n",
       "      <td>0.330952</td>\n",
       "      <td>blue</td>\n",
       "      <td>2500</td>\n",
       "      <td>blue</td>\n",
       "      <td>...</td>\n",
       "      <td>gold</td>\n",
       "      <td>500</td>\n",
       "      <td>orange</td>\n",
       "      <td>2500</td>\n",
       "      <td>blue</td>\n",
       "      <td>2500</td>\n",
       "      <td>blue</td>\n",
       "      <td>2500</td>\n",
       "      <td>green</td>\n",
       "      <td>2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>user_1024</td>\n",
       "      <td>18</td>\n",
       "      <td>247</td>\n",
       "      <td>3118</td>\n",
       "      <td>1360</td>\n",
       "      <td>0.004818</td>\n",
       "      <td>0.383896</td>\n",
       "      <td>blue</td>\n",
       "      <td>2500</td>\n",
       "      <td>red</td>\n",
       "      <td>...</td>\n",
       "      <td>red</td>\n",
       "      <td>2500</td>\n",
       "      <td>crimson</td>\n",
       "      <td>2500</td>\n",
       "      <td>blue</td>\n",
       "      <td>2500</td>\n",
       "      <td>red</td>\n",
       "      <td>2500</td>\n",
       "      <td>blue</td>\n",
       "      <td>2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>user_11029</td>\n",
       "      <td>49</td>\n",
       "      <td>50</td>\n",
       "      <td>9782</td>\n",
       "      <td>10720</td>\n",
       "      <td>0.007205</td>\n",
       "      <td>0.252049</td>\n",
       "      <td>red</td>\n",
       "      <td>2500</td>\n",
       "      <td>blue</td>\n",
       "      <td>...</td>\n",
       "      <td>blue</td>\n",
       "      <td>2500</td>\n",
       "      <td>orange</td>\n",
       "      <td>2500</td>\n",
       "      <td>blue</td>\n",
       "      <td>2500</td>\n",
       "      <td>green</td>\n",
       "      <td>2500</td>\n",
       "      <td>red</td>\n",
       "      <td>2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>user_1106</td>\n",
       "      <td>13</td>\n",
       "      <td>34</td>\n",
       "      <td>1282</td>\n",
       "      <td>1435</td>\n",
       "      <td>0.055707</td>\n",
       "      <td>0.366349</td>\n",
       "      <td>blue</td>\n",
       "      <td>2500</td>\n",
       "      <td>red</td>\n",
       "      <td>...</td>\n",
       "      <td>red</td>\n",
       "      <td>2500</td>\n",
       "      <td>crimson</td>\n",
       "      <td>2500</td>\n",
       "      <td>blue</td>\n",
       "      <td>2500</td>\n",
       "      <td>red</td>\n",
       "      <td>2500</td>\n",
       "      <td>blue</td>\n",
       "      <td>2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>user_11431</td>\n",
       "      <td>20</td>\n",
       "      <td>3602</td>\n",
       "      <td>7478</td>\n",
       "      <td>7254</td>\n",
       "      <td>0.081220</td>\n",
       "      <td>0.457911</td>\n",
       "      <td>red</td>\n",
       "      <td>2500</td>\n",
       "      <td>blue</td>\n",
       "      <td>...</td>\n",
       "      <td>blue</td>\n",
       "      <td>2500</td>\n",
       "      <td>orange</td>\n",
       "      <td>2500</td>\n",
       "      <td>blue</td>\n",
       "      <td>2500</td>\n",
       "      <td>green</td>\n",
       "      <td>2500</td>\n",
       "      <td>red</td>\n",
       "      <td>2500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  screen_name  total_tweet_count  total_retweet_count  max_followers_count  \\\n",
       "0  user_10155                  9                 3511                46494   \n",
       "1   user_1024                 18                  247                 3118   \n",
       "2  user_11029                 49                   50                 9782   \n",
       "3   user_1106                 13                   34                 1282   \n",
       "4  user_11431                 20                 3602                 7478   \n",
       "\n",
       "   max_friends_count  agg_sentiment_polarity  agg_sentiment_subjectivity  \\\n",
       "0                778                0.154563                    0.330952   \n",
       "1               1360                0.004818                    0.383896   \n",
       "2              10720                0.007205                    0.252049   \n",
       "3               1435                0.055707                    0.366349   \n",
       "4               7254                0.081220                    0.457911   \n",
       "\n",
       "  kernighanLin_ID  kernighanLin_size GModularity_ID     ...      kClique_ID  \\\n",
       "0            blue               2500           blue     ...            gold   \n",
       "1            blue               2500            red     ...             red   \n",
       "2             red               2500           blue     ...            blue   \n",
       "3            blue               2500            red     ...             red   \n",
       "4             red               2500           blue     ...            blue   \n",
       "\n",
       "  kClique_size  labelProp_ID labelProp_size  girvanNew_ID girvanNew_size  \\\n",
       "0          500        orange           2500          blue           2500   \n",
       "1         2500       crimson           2500          blue           2500   \n",
       "2         2500        orange           2500          blue           2500   \n",
       "3         2500       crimson           2500          blue           2500   \n",
       "4         2500        orange           2500          blue           2500   \n",
       "\n",
       "   louvain_ID louvain_size  leiden_ID leiden_size  \n",
       "0        blue         2500      green        2500  \n",
       "1         red         2500       blue        2500  \n",
       "2       green         2500        red        2500  \n",
       "3         red         2500       blue        2500  \n",
       "4       green         2500        red        2500  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "color_list = ['blue','red','green','brown','orange','crimson','cyan','pink','darkslategray','darkgreen','olive']\n",
    "community_df['kernighanLin_ID'] = community_df['kernighanLin_ID'].astype(str)\n",
    "community_df['kClique_ID'] = community_df['kClique_ID'].astype(str)\n",
    "community_df['GModularity_ID'] = community_df['GModularity_ID'].astype(str)\n",
    "community_df['labelProp_ID'] = community_df['labelProp_ID'].astype(str)\n",
    "community_df['girvanNew_ID'] = community_df['girvanNew_ID'].astype(str)\n",
    "community_df['louvain_ID'] = community_df['louvain_ID'].astype(str)\n",
    "community_df['leiden_ID'] = community_df['leiden_ID'].astype(str)\n",
    "for c in range(len(color_list)):\n",
    "    community_df['kernighanLin_ID'] = community_df['kernighanLin_ID'].replace(str(c),color_list[c])\n",
    "    community_df['kClique_ID'] = community_df['kClique_ID'].replace(str(c),color_list[c])\n",
    "    community_df['GModularity_ID'] = community_df['GModularity_ID'].replace(str(c),color_list[c])\n",
    "    community_df['labelProp_ID'] = community_df['labelProp_ID'].replace(str(c),color_list[c])\n",
    "    community_df['girvanNew_ID'] = community_df['girvanNew_ID'].replace(str(c),color_list[c])\n",
    "    community_df['louvain_ID'] = community_df['louvain_ID'].replace(str(c),color_list[c])\n",
    "    community_df['leiden_ID'] = community_df['leiden_ID'].replace(str(c),color_list[c])\n",
    "community_df['kernighanLin_ID'] = community_df['kernighanLin_ID'].replace('','gold')\n",
    "community_df['kClique_ID'] = community_df['kClique_ID'].replace('','gold')\n",
    "community_df['GModularity_ID'] = community_df['GModularity_ID'].replace('','gold')\n",
    "community_df['labelProp_ID'] = community_df['labelProp_ID'].replace('','gold')\n",
    "community_df['girvanNew_ID'] = community_df['girvanNew_ID'].replace('','gold')\n",
    "community_df['louvain_ID'] = community_df['louvain_ID'].replace('','gold')\n",
    "community_df['leiden_ID'] = community_df['leiden_ID'].replace('','gold')\n",
    "community_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nplt.figure(figsize=(75,75))\\npos = nx.spring_layout(G, k=2*1/np.sqrt(len(G.nodes())), iterations=30)\\nnx.draw(G,pos=pos,with_labels = True,font_size=50,node_size=size_of_nodes,node_color=color_of_nodes,seed=1)\\nplt.savefig(\"kernighan_lin_community_\"+str(retweet_threshold)+\".jpeg\")\\nplt.show() #display\\n'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes = list(community_df['screen_name'])\n",
    "size_of_nodes = list(community_df['kernighanLin_size'])\n",
    "color_of_nodes = list(community_df['kernighanLin_ID']) #Multiply by 2 to see more contrast in colors\n",
    "mutual_follow_lol = network_df[['source_screen_name','destination_screen_name']][network_df['has_mutual_following']==True].values.tolist()\n",
    "mutual_follow_edges = []\n",
    "for mfe in mutual_follow_lol:\n",
    "    mutual_follow_edges.append((mfe[0],mfe[1]))\n",
    "\n",
    "G = nx.Graph()\n",
    "G.add_nodes_from(nodes)\n",
    "G.add_edges_from(mutual_follow_edges)\n",
    "'''\n",
    "plt.figure(figsize=(75,75))\n",
    "pos = nx.spring_layout(G, k=2*1/np.sqrt(len(G.nodes())), iterations=30)\n",
    "nx.draw(G,pos=pos,with_labels = True,font_size=50,node_size=size_of_nodes,node_color=color_of_nodes,seed=1)\n",
    "plt.savefig(\"kernighan_lin_community_\"+str(retweet_threshold)+\".jpeg\")\n",
    "plt.show() #display\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kernighan Lin Community\n",
    "<img src=\"Images/kernighan_lin_community_10.jpeg\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nplt.figure(figsize=(75,75))\\npos = nx.spring_layout(G, k=2*1/np.sqrt(len(G.nodes())), iterations=30)\\nnx.draw(G,pos=pos,with_labels = True,font_size=50,node_size=size_of_nodes,node_color=color_of_nodes,seed=1)\\nplt.savefig(\"k_clique_community_\"+str(retweet_threshold)+\".jpeg\")\\nplt.show() #display\\n'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes = list(community_df['screen_name'])\n",
    "size_of_nodes = list(community_df['kClique_size'])\n",
    "color_of_nodes = list(community_df['kClique_ID']) #Multiply by 2 to see more contrast in colors\n",
    "mutual_follow_lol = network_df[['source_screen_name','destination_screen_name']][network_df['has_mutual_following']==True].values.tolist()\n",
    "mutual_follow_edges = []\n",
    "for mfe in mutual_follow_lol:\n",
    "    mutual_follow_edges.append((mfe[0],mfe[1]))\n",
    "\n",
    "G = nx.Graph()\n",
    "G.add_nodes_from(nodes)\n",
    "G.add_edges_from(mutual_follow_edges)\n",
    "'''\n",
    "plt.figure(figsize=(75,75))\n",
    "pos = nx.spring_layout(G, k=2*1/np.sqrt(len(G.nodes())), iterations=30)\n",
    "nx.draw(G,pos=pos,with_labels = True,font_size=50,node_size=size_of_nodes,node_color=color_of_nodes,seed=1)\n",
    "plt.savefig(\"k_clique_community_\"+str(retweet_threshold)+\".jpeg\")\n",
    "plt.show() #display\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-Clique Community\n",
    "<img src='Images/k_clique_community_10.jpeg'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nplt.figure(figsize=(75,75))\\npos = nx.spring_layout(G, k=1.5*1/np.sqrt(len(G.nodes())), iterations=25)\\nnx.draw(G,pos=pos,with_labels = True,font_size=50,node_size=size_of_nodes,node_color=color_of_nodes,seed=10)\\nplt.savefig(\"greedy_modularity_community_\"+str(retweet_threshold)+\".jpeg\")\\nplt.show() #display\\n'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes = list(community_df['screen_name'])\n",
    "size_of_nodes = list(community_df['GModularity_size'])\n",
    "color_of_nodes = list(community_df['GModularity_ID']) #Multiply by 2 to see more contrast in colors\n",
    "mutual_follow_lol = network_df[['source_screen_name','destination_screen_name']][network_df['has_mutual_following']==True].values.tolist()\n",
    "mutual_follow_edges = []\n",
    "for mfe in mutual_follow_lol:\n",
    "    mutual_follow_edges.append((mfe[0],mfe[1]))\n",
    "\n",
    "G = nx.Graph()\n",
    "G.add_nodes_from(nodes)\n",
    "G.add_edges_from(mutual_follow_edges)\n",
    "'''\n",
    "plt.figure(figsize=(75,75))\n",
    "pos = nx.spring_layout(G, k=1.5*1/np.sqrt(len(G.nodes())), iterations=25)\n",
    "nx.draw(G,pos=pos,with_labels = True,font_size=50,node_size=size_of_nodes,node_color=color_of_nodes,seed=10)\n",
    "plt.savefig(\"greedy_modularity_community_\"+str(retweet_threshold)+\".jpeg\")\n",
    "plt.show() #display\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Greedy Modularity Community\n",
    "<img src='Images/greedy_modularity_community_10.jpeg'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nplt.figure(figsize=(75,75))\\npos = nx.spring_layout(G, k=1.5*1/np.sqrt(len(G.nodes())), iterations=25)\\nnx.draw(G,pos=pos,with_labels = True,font_size=50,node_size=size_of_nodes,node_color=color_of_nodes,seed=10)\\nplt.savefig(\"label_propagation_community_\"+str(retweet_threshold)+\".jpeg\")\\nplt.show() #display\\n'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes = list(community_df['screen_name'])\n",
    "size_of_nodes = list(community_df['labelProp_size'])\n",
    "color_of_nodes = list(community_df['labelProp_ID']) #Multiply by 2 to see more contrast in colors\n",
    "mutual_follow_lol = network_df[['source_screen_name','destination_screen_name']][network_df['has_mutual_following']==True].values.tolist()\n",
    "mutual_follow_edges = []\n",
    "for mfe in mutual_follow_lol:\n",
    "    mutual_follow_edges.append((mfe[0],mfe[1]))\n",
    "\n",
    "G = nx.Graph()\n",
    "G.add_nodes_from(nodes)\n",
    "G.add_edges_from(mutual_follow_edges)\n",
    "'''\n",
    "plt.figure(figsize=(75,75))\n",
    "pos = nx.spring_layout(G, k=1.5*1/np.sqrt(len(G.nodes())), iterations=25)\n",
    "nx.draw(G,pos=pos,with_labels = True,font_size=50,node_size=size_of_nodes,node_color=color_of_nodes,seed=10)\n",
    "plt.savefig(\"label_propagation_community_\"+str(retweet_threshold)+\".jpeg\")\n",
    "plt.show() #display\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Label Propagation Community\n",
    "<img src='Images/label_propagation_community_10.jpeg'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nplt.figure(figsize=(75,75))\\npos = nx.spring_layout(G, k=1.5*1/np.sqrt(len(G.nodes())), iterations=25)\\nnx.draw(G,pos=pos,with_labels = True,font_size=50,node_size=size_of_nodes,node_color=color_of_nodes,seed=10)\\nplt.savefig(\"girvan_newman_community_\"+str(retweet_threshold)+\".jpeg\")\\nplt.show() #display\\n'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes = list(community_df['screen_name'])\n",
    "size_of_nodes = list(community_df['girvanNew_size'])\n",
    "color_of_nodes = list(community_df['girvanNew_ID']) #Multiply by 2 to see more contrast in colors\n",
    "mutual_follow_lol = network_df[['source_screen_name','destination_screen_name']][network_df['has_mutual_following']==True].values.tolist()\n",
    "mutual_follow_edges = []\n",
    "for mfe in mutual_follow_lol:\n",
    "    mutual_follow_edges.append((mfe[0],mfe[1]))\n",
    "\n",
    "G = nx.Graph()\n",
    "G.add_nodes_from(nodes)\n",
    "G.add_edges_from(mutual_follow_edges)\n",
    "'''\n",
    "plt.figure(figsize=(75,75))\n",
    "pos = nx.spring_layout(G, k=1.5*1/np.sqrt(len(G.nodes())), iterations=25)\n",
    "nx.draw(G,pos=pos,with_labels = True,font_size=50,node_size=size_of_nodes,node_color=color_of_nodes,seed=10)\n",
    "plt.savefig(\"girvan_newman_community_\"+str(retweet_threshold)+\".jpeg\")\n",
    "plt.show() #display\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Girvan-Newman Community\n",
    "<img src='Images/girvan_newman_community_10.jpeg'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nplt.figure(figsize=(75,75))\\npos = nx.spring_layout(G, k=1.5*1/np.sqrt(len(G.nodes())), iterations=25)\\nnx.draw(G,pos=pos,with_labels = True,font_size=50,node_size=size_of_nodes,node_color=color_of_nodes,seed=10)\\nplt.savefig(\"louvain_method_community_\"+str(retweet_threshold)+\".jpeg\")\\nplt.show() #display\\n'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes = list(community_df['screen_name'])\n",
    "size_of_nodes = list(community_df['louvain_size'])\n",
    "color_of_nodes = list(community_df['louvain_ID']) #Multiply by 2 to see more contrast in colors\n",
    "mutual_follow_lol = network_df[['source_screen_name','destination_screen_name']][network_df['has_mutual_following']==True].values.tolist()\n",
    "mutual_follow_edges = []\n",
    "for mfe in mutual_follow_lol:\n",
    "    mutual_follow_edges.append((mfe[0],mfe[1]))\n",
    "\n",
    "G = nx.Graph()\n",
    "G.add_nodes_from(nodes)\n",
    "G.add_edges_from(mutual_follow_edges)\n",
    "'''\n",
    "plt.figure(figsize=(75,75))\n",
    "pos = nx.spring_layout(G, k=1.5*1/np.sqrt(len(G.nodes())), iterations=25)\n",
    "nx.draw(G,pos=pos,with_labels = True,font_size=50,node_size=size_of_nodes,node_color=color_of_nodes,seed=10)\n",
    "plt.savefig(\"louvain_method_community_\"+str(retweet_threshold)+\".jpeg\")\n",
    "plt.show() #display\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Louvain Method\n",
    "<img src='Images/louvain_method_community_10.jpeg'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nplt.figure(figsize=(75,75))\\npos = nx.spring_layout(G, k=1.5*1/np.sqrt(len(G.nodes())), iterations=25)\\nnx.draw(G,pos=pos,with_labels = True,font_size=50,node_size=size_of_nodes,node_color=color_of_nodes,seed=10)\\nplt.savefig(\"leiden_method_community_\"+str(retweet_threshold)+\".jpeg\")\\nplt.show() #display\\n'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes = list(community_df['screen_name'])\n",
    "size_of_nodes = list(community_df['leiden_size'])\n",
    "color_of_nodes = list(community_df['leiden_ID']) #Multiply by 2 to see more contrast in colors\n",
    "mutual_follow_lol = network_df[['source_screen_name','destination_screen_name']][network_df['has_mutual_following']==True].values.tolist()\n",
    "mutual_follow_edges = []\n",
    "for mfe in mutual_follow_lol:\n",
    "    mutual_follow_edges.append((mfe[0],mfe[1]))\n",
    "\n",
    "G = nx.Graph()\n",
    "G.add_nodes_from(nodes)\n",
    "G.add_edges_from(mutual_follow_edges)\n",
    "'''\n",
    "plt.figure(figsize=(75,75))\n",
    "pos = nx.spring_layout(G, k=1.5*1/np.sqrt(len(G.nodes())), iterations=25)\n",
    "nx.draw(G,pos=pos,with_labels = True,font_size=50,node_size=size_of_nodes,node_color=color_of_nodes,seed=10)\n",
    "plt.savefig(\"leiden_method_community_\"+str(retweet_threshold)+\".jpeg\")\n",
    "plt.show() #display\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leiden Method\n",
    "<img src='Images/leiden_method_community_10.jpeg'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of Community algorithms based on Sentiments about Brexit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(240, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>screen_name</th>\n",
       "      <th>week1_sentiment</th>\n",
       "      <th>week2_sentiment</th>\n",
       "      <th>week3_sentiment</th>\n",
       "      <th>week4_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>user_10155</td>\n",
       "      <td>0.154563</td>\n",
       "      <td>0.056186</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>-0.093750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>user_1024</td>\n",
       "      <td>0.004818</td>\n",
       "      <td>-0.041788</td>\n",
       "      <td>0.231871</td>\n",
       "      <td>0.093469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>user_11029</td>\n",
       "      <td>0.007205</td>\n",
       "      <td>-0.038345</td>\n",
       "      <td>0.018403</td>\n",
       "      <td>-0.022658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>user_1106</td>\n",
       "      <td>0.055707</td>\n",
       "      <td>0.018275</td>\n",
       "      <td>0.051210</td>\n",
       "      <td>0.029384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>user_11431</td>\n",
       "      <td>0.081220</td>\n",
       "      <td>0.164103</td>\n",
       "      <td>0.102105</td>\n",
       "      <td>0.034583</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  screen_name  week1_sentiment  week2_sentiment  week3_sentiment  \\\n",
       "0  user_10155         0.154563         0.056186         0.160000   \n",
       "1   user_1024         0.004818        -0.041788         0.231871   \n",
       "2  user_11029         0.007205        -0.038345         0.018403   \n",
       "3   user_1106         0.055707         0.018275         0.051210   \n",
       "4  user_11431         0.081220         0.164103         0.102105   \n",
       "\n",
       "   week4_sentiment  \n",
       "0        -0.093750  \n",
       "1         0.093469  \n",
       "2        -0.022658  \n",
       "3         0.029384  \n",
       "4         0.034583  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Display the aggregate sentiment of the twitter users for each week\n",
    "all_week_sentiment_df = pd.concat((network_stats_df_week1[['screen_name','agg_sentiment_polarity']].rename(columns={'agg_sentiment_polarity':'week1_sentiment'}),\n",
    "                          network_stats_df_week2[['screen_name','agg_sentiment_polarity']].rename(columns={'agg_sentiment_polarity':'week2_sentiment','screen_name':'screen_name_2'}),\n",
    "                          network_stats_df_week3[['screen_name','agg_sentiment_polarity']].rename(columns={'agg_sentiment_polarity':'week3_sentiment','screen_name':'screen_name_3'}),\n",
    "                          network_stats_df_week4[['screen_name','agg_sentiment_polarity']].rename(columns={'agg_sentiment_polarity':'week4_sentiment','screen_name':'screen_name_4'})\n",
    "                          ),axis=1)\n",
    "all_week_sentiment_df = all_week_sentiment_df.drop(['screen_name_2','screen_name_3','screen_name_4'],axis=1)\n",
    "print(all_week_sentiment_df.shape)\n",
    "all_week_sentiment_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(240, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>screen_name</th>\n",
       "      <th>kernighanLin_ID</th>\n",
       "      <th>GModularity_ID</th>\n",
       "      <th>kClique_ID</th>\n",
       "      <th>labelProp_ID</th>\n",
       "      <th>girvanNew_ID</th>\n",
       "      <th>louvain_ID</th>\n",
       "      <th>leiden_ID</th>\n",
       "      <th>week1_sentiment</th>\n",
       "      <th>week2_sentiment</th>\n",
       "      <th>week3_sentiment</th>\n",
       "      <th>week4_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>user_10155</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.154563</td>\n",
       "      <td>0.056186</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>-0.093750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>user_1024</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.004818</td>\n",
       "      <td>-0.041788</td>\n",
       "      <td>0.231871</td>\n",
       "      <td>0.093469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>user_11029</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.007205</td>\n",
       "      <td>-0.038345</td>\n",
       "      <td>0.018403</td>\n",
       "      <td>-0.022658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>user_1106</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.055707</td>\n",
       "      <td>0.018275</td>\n",
       "      <td>0.051210</td>\n",
       "      <td>0.029384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>user_11431</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.081220</td>\n",
       "      <td>0.164103</td>\n",
       "      <td>0.102105</td>\n",
       "      <td>0.034583</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  screen_name kernighanLin_ID GModularity_ID kClique_ID labelProp_ID  \\\n",
       "0  user_10155               0              0                       4   \n",
       "1   user_1024               0              1          1            5   \n",
       "2  user_11029               1              0          0            4   \n",
       "3   user_1106               0              1          1            5   \n",
       "4  user_11431               1              0          0            4   \n",
       "\n",
       "  girvanNew_ID louvain_ID  leiden_ID  week1_sentiment  week2_sentiment  \\\n",
       "0            0          0          2         0.154563         0.056186   \n",
       "1            0          1          0         0.004818        -0.041788   \n",
       "2            0          2          1         0.007205        -0.038345   \n",
       "3            0          1          0         0.055707         0.018275   \n",
       "4            0          2          1         0.081220         0.164103   \n",
       "\n",
       "   week3_sentiment  week4_sentiment  \n",
       "0         0.160000        -0.093750  \n",
       "1         0.231871         0.093469  \n",
       "2         0.018403        -0.022658  \n",
       "3         0.051210         0.029384  \n",
       "4         0.102105         0.034583  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_df = pd.DataFrame()\n",
    "node_df['screen_name'] = list(network_stats_df_week1['screen_name'])\n",
    "nw_community_df = pd.merge(tweet_df[['screen_name','retweet_count']].copy(),node_df,on='screen_name',how='inner')\n",
    "nw_community_df = nw_community_df.groupby('screen_name').sum()\n",
    "nw_community_df.reset_index(inplace=True)\n",
    "nw_community_df['retweet_count'] = nw_community_df['retweet_count'].astype(float)\n",
    "nw_community_df['kernighanLin_ID'] = '' #Bipartitian\n",
    "nw_community_df['GModularity_ID'] = ''\n",
    "nw_community_df['kClique_ID'] = ''\n",
    "nw_community_df['labelProp_ID'] = ''\n",
    "nw_community_df['girvanNew_ID'] = ''\n",
    "nw_community_df['louvain_ID'] = ''\n",
    "for index,row in nw_community_df.iterrows():\n",
    "    for h in range(len(network_community_kl)):\n",
    "        if row['screen_name'] in network_community_kl[h]:\n",
    "            nw_community_df.at[index,'kernighanLin_ID'] = h\n",
    "    for i in range(len(network_community_modularity)):\n",
    "        if row['screen_name'] in network_community_modularity[i]:\n",
    "            nw_community_df.at[index,'GModularity_ID'] = i\n",
    "    for j in range(len(network_community_k_clique)):\n",
    "        if row['screen_name'] in network_community_k_clique[j]:\n",
    "            nw_community_df.at[index,'kClique_ID'] = j\n",
    "    for k in range(len(network_community_lpa)):\n",
    "        if row['screen_name'] in network_community_lpa[k]:\n",
    "            nw_community_df.at[index,'labelProp_ID'] = k\n",
    "    for l in range(len(network_community_gn)):\n",
    "        if row['screen_name'] in network_community_gn[l]:\n",
    "            nw_community_df.at[index,'girvanNew_ID'] = l\n",
    "    for m in range(len(network_community_louvain)):\n",
    "        if row['screen_name'] in network_community_louvain[m]:\n",
    "            nw_community_df.at[index,'louvain_ID'] = m\n",
    "\n",
    "leiden_df = pd.read_csv('leiden_df.csv')[['screen_name','leiden_ID']]\n",
    "leiden_df['screen_name'] = leiden_df['screen_name'].map(mapping_dict)\n",
    "nw_community_df = pd.merge(nw_community_df,leiden_df,on='screen_name',how='inner')\n",
    "nw_community_df = nw_community_df.drop(['retweet_count'],axis=1)\n",
    "\n",
    "community_validation_df = pd.merge(nw_community_df,all_week_sentiment_df,on='screen_name',how='inner')\n",
    "print(community_validation_df.shape)\n",
    "community_validation_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>screen_name</th>\n",
       "      <th>kernighanLin_ID</th>\n",
       "      <th>GModularity_ID</th>\n",
       "      <th>kClique_ID</th>\n",
       "      <th>labelProp_ID</th>\n",
       "      <th>girvanNew_ID</th>\n",
       "      <th>louvain_ID</th>\n",
       "      <th>leiden_ID</th>\n",
       "      <th>week1_sentiment</th>\n",
       "      <th>week2_sentiment</th>\n",
       "      <th>week3_sentiment</th>\n",
       "      <th>week4_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>user_10155</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.587082</td>\n",
       "      <td>0.525253</td>\n",
       "      <td>0.620118</td>\n",
       "      <td>0.294570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>user_1024</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.408083</td>\n",
       "      <td>0.373640</td>\n",
       "      <td>0.696668</td>\n",
       "      <td>0.524757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>user_11029</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.410936</td>\n",
       "      <td>0.378969</td>\n",
       "      <td>0.469305</td>\n",
       "      <td>0.381978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>user_1106</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.468913</td>\n",
       "      <td>0.466587</td>\n",
       "      <td>0.504247</td>\n",
       "      <td>0.445964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>user_11431</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.499411</td>\n",
       "      <td>0.692251</td>\n",
       "      <td>0.558455</td>\n",
       "      <td>0.452357</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  screen_name kernighanLin_ID GModularity_ID kClique_ID labelProp_ID  \\\n",
       "0  user_10155               0              0                       4   \n",
       "1   user_1024               0              1          1            5   \n",
       "2  user_11029               1              0          0            4   \n",
       "3   user_1106               0              1          1            5   \n",
       "4  user_11431               1              0          0            4   \n",
       "\n",
       "  girvanNew_ID louvain_ID  leiden_ID  week1_sentiment  week2_sentiment  \\\n",
       "0            0          0          2         0.587082         0.525253   \n",
       "1            0          1          0         0.408083         0.373640   \n",
       "2            0          2          1         0.410936         0.378969   \n",
       "3            0          1          0         0.468913         0.466587   \n",
       "4            0          2          1         0.499411         0.692251   \n",
       "\n",
       "   week3_sentiment  week4_sentiment  \n",
       "0         0.620118         0.294570  \n",
       "1         0.696668         0.524757  \n",
       "2         0.469305         0.381978  \n",
       "3         0.504247         0.445964  \n",
       "4         0.558455         0.452357  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "community_validation_df[['week1_sentiment','week2_sentiment','week3_sentiment','week4_sentiment']] = scaler.fit_transform(community_validation_df[['week1_sentiment','week2_sentiment','week3_sentiment','week4_sentiment']])\n",
    "community_validation_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_sentiment_CV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Kernighan-Lin</th>\n",
       "      <td>0.259036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Greedy Modularity</th>\n",
       "      <td>0.211898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>k-Clique</th>\n",
       "      <td>0.254298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Label-Propagation</th>\n",
       "      <td>0.182775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Girvan-Newman</th>\n",
       "      <td>0.184610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Louvain Method</th>\n",
       "      <td>0.224880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Leiden Method</th>\n",
       "      <td>0.224992</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   mean_sentiment_CV\n",
       "Kernighan-Lin               0.259036\n",
       "Greedy Modularity           0.211898\n",
       "k-Clique                    0.254298\n",
       "Label-Propagation           0.182775\n",
       "Girvan-Newman               0.184610\n",
       "Louvain Method              0.224880\n",
       "Leiden Method               0.224992"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comm_cols = ['mean_sentiment_CV']\n",
    "community_sent_cv_df = pd.DataFrame(columns = comm_cols)\n",
    "community_alg = {'Kernighan-Lin':'kernighanLin_ID','Greedy Modularity':'GModularity_ID','k-Clique':'kClique_ID',\n",
    "                 'Label-Propagation':'labelProp_ID','Girvan-Newman':'girvanNew_ID','Louvain Method':'louvain_ID',\n",
    "                 'Leiden Method':'leiden_ID'}\n",
    "for key,value in community_alg.items():\n",
    "    df = community_validation_df[[value,'week1_sentiment','week2_sentiment','week3_sentiment','week4_sentiment']].copy()\n",
    "    mean_cv = np.mean(np.mean(df.groupby(value).std()/df.groupby(value).mean()))\n",
    "    df = pd.DataFrame([mean_cv],columns=comm_cols,index=[key])\n",
    "    community_sent_cv_df = community_sent_cv_df.append(df)\n",
    "community_sent_cv_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above table shows the mean co-efficient of variation in sentiments about #Brexit among the communities detected by various community detection algorithms. The variance tells us that the communities formed by the algorithm have users whose sentiments are varying to that level. So, the algorithm having the least average variance, is the one which is able to detect the communities with like minded users, who expressed similarity in their opinions and hence least variance. <br>\n",
    "So from the above table, for this social network, <b><i>Label-Propagation</i></b> community detection algorithm divided the network such that the members of each communities share similar ideas about #Brexit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_sentiment_CV_week1</th>\n",
       "      <th>mean_sentiment_CV_week2</th>\n",
       "      <th>mean_sentiment_CV_week3</th>\n",
       "      <th>mean_sentiment_CV_week4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Kernighan-Lin</th>\n",
       "      <td>0.225892</td>\n",
       "      <td>0.253841</td>\n",
       "      <td>0.254636</td>\n",
       "      <td>0.301774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Greedy Modularity</th>\n",
       "      <td>0.195532</td>\n",
       "      <td>0.209860</td>\n",
       "      <td>0.237113</td>\n",
       "      <td>0.205085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>k-Clique</th>\n",
       "      <td>0.228701</td>\n",
       "      <td>0.248205</td>\n",
       "      <td>0.242319</td>\n",
       "      <td>0.297966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Label-Propagation</th>\n",
       "      <td>0.214525</td>\n",
       "      <td>0.200492</td>\n",
       "      <td>0.176703</td>\n",
       "      <td>0.139379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Girvan-Newman</th>\n",
       "      <td>0.201543</td>\n",
       "      <td>0.197264</td>\n",
       "      <td>0.198285</td>\n",
       "      <td>0.141350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Louvain Method</th>\n",
       "      <td>0.201771</td>\n",
       "      <td>0.226227</td>\n",
       "      <td>0.242140</td>\n",
       "      <td>0.229384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Leiden Method</th>\n",
       "      <td>0.202053</td>\n",
       "      <td>0.226074</td>\n",
       "      <td>0.242723</td>\n",
       "      <td>0.229120</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   mean_sentiment_CV_week1  mean_sentiment_CV_week2  \\\n",
       "Kernighan-Lin                     0.225892                 0.253841   \n",
       "Greedy Modularity                 0.195532                 0.209860   \n",
       "k-Clique                          0.228701                 0.248205   \n",
       "Label-Propagation                 0.214525                 0.200492   \n",
       "Girvan-Newman                     0.201543                 0.197264   \n",
       "Louvain Method                    0.201771                 0.226227   \n",
       "Leiden Method                     0.202053                 0.226074   \n",
       "\n",
       "                   mean_sentiment_CV_week3  mean_sentiment_CV_week4  \n",
       "Kernighan-Lin                     0.254636                 0.301774  \n",
       "Greedy Modularity                 0.237113                 0.205085  \n",
       "k-Clique                          0.242319                 0.297966  \n",
       "Label-Propagation                 0.176703                 0.139379  \n",
       "Girvan-Newman                     0.198285                 0.141350  \n",
       "Louvain Method                    0.242140                 0.229384  \n",
       "Leiden Method                     0.242723                 0.229120  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Same as above, but show the results week-wise\n",
    "comm_cols = ['mean_sentiment_CV_week1','mean_sentiment_CV_week2','mean_sentiment_CV_week3','mean_sentiment_CV_week4']\n",
    "community_sent_cv_df = pd.DataFrame(columns = comm_cols)\n",
    "community_alg = {'Kernighan-Lin':'kernighanLin_ID','Greedy Modularity':'GModularity_ID','k-Clique':'kClique_ID',\n",
    "                 'Label-Propagation':'labelProp_ID','Girvan-Newman':'girvanNew_ID','Louvain Method':'louvain_ID',\n",
    "                 'Leiden Method':'leiden_ID'}\n",
    "for key,value in community_alg.items():\n",
    "    df = community_validation_df[[value,'week1_sentiment','week2_sentiment','week3_sentiment','week4_sentiment']].copy()\n",
    "    mean_cv = np.mean(df.groupby(value).std()/df.groupby(value).mean())\n",
    "    df = pd.DataFrame([[mean_cv[0],mean_cv[1],mean_cv[2],mean_cv[3]]],\n",
    "                      columns=comm_cols,index=[key])\n",
    "    community_sent_cv_df = community_sent_cv_df.append(df)\n",
    "community_sent_cv_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
